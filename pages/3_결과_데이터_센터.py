import streamlit as st
import pandas as pd
import json
import os
import re
import numpy as np

st.set_page_config(page_title="ê²°ê³¼ ë°ì´í„° ì„¼í„°", page_icon="ğŸ“Š", layout="wide")

st.title("ğŸ“Š ê²°ê³¼ ë°ì´í„° ì„¼í„°")
st.markdown("ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ **ë°ì´í„° ìœ íš¨ì„±(CR)**ì„ ê²€ì¦í•˜ê³  **ìµœì¢… ìˆœìœ„**ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤.")

DATA_FOLDER = "survey_data"

# ==============================================================================
# [AHP ê³„ì‚° ì—”ì§„]
# ==============================================================================
RI_TABLE = {1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45}

def saaty_scale(val):
    val = int(val)
    if val == 0: return 1
    elif val < 0: return 1 / (abs(val) + 1)
    else: return val + 1

def calculate_ahp(items, pairs_data):
    """ê°€ì¤‘ì¹˜ì™€ CR(ì¼ê´€ì„± ë¹„ìœ¨)ì„ ë™ì‹œì— ê³„ì‚°"""
    n = len(items)
    if n == 0: return {}, 0
    
    matrix = np.ones((n, n))
    item_map = {name: i for i, name in enumerate(items)}

    for key, val in pairs_data.items():
        # [ìˆ˜ì •ë¨] êµ¬ë¶„ìë¥¼ " vs "ë¡œ ë³€ê²½í•˜ê³ , ì–‘ìª½ ê³µë°± ì œê±°
        if " vs " in key:
            parts = key.split(" vs ")
            item_a, item_b = parts[0].strip(), parts[1].strip()
            
            if item_a in item_map and item_b in item_map:
                idx_a, idx_b = item_map[item_a], item_map[item_b]
                scale_val = saaty_scale(val)
                matrix[idx_a][idx_b] = scale_val
                matrix[idx_b][idx_a] = 1 / scale_val

    # 1. ê°€ì¤‘ì¹˜ ê³„ì‚° (ê¸°í•˜í‰ê· ë²•)
    geo_means = []
    for i in range(n):
        row_prod = np.prod(matrix[i])
        geo_means.append(row_prod ** (1/n))
    
    total_sum = sum(geo_means)
    weights = [gm / total_sum for gm in geo_means]
    weights_dict = {items[i]: w for i, w in enumerate(weights)}

    # 2. CR ê³„ì‚°
    if n <= 2:
        cr = 0.0
    else:
        lambda_max = 0
        for i in range(n):
            col_sum = np.sum(matrix[:, i])
            lambda_max += col_sum * weights[i]
            
        ci = (lambda_max - n) / (n - 1)
        ri = RI_TABLE.get(n, 1.49)
        cr = ci / ri if ri != 0 else 0

    return weights_dict, cr

def process_single_response(raw_json):
    """í•œ ëª…ì˜ ì‘ë‹µ ë°ì´í„°ë¥¼ ë¶„ì„"""
    try:
        data = json.loads(raw_json)
    except:
        return None, 9.9

    groups, items_in_group = {}, {}

    # ë°ì´í„° íŒŒì‹±
    for full_key, val in data.items():
        # ì •ê·œí‘œí˜„ì‹: [ê·¸ë£¹ëª…] í•­ëª©A vs í•­ëª©B
        match = re.match(r"\[(.*?)\](.*)", full_key)
        if match:
            group_name, pair_key = match.group(1), match.group(2).strip()
            
            if group_name not in groups: 
                groups[group_name] = {}
                items_in_group[group_name] = set()
            
            groups[group_name][pair_key] = val
            
            # [ìˆ˜ì •ë¨] êµ¬ë¶„ì " vs " ì²˜ë¦¬
            if " vs " in pair_key:
                a, b = pair_key.split(" vs ")
                items_in_group[group_name].add(a.strip())
                items_in_group[group_name].add(b.strip())

    # ê³„ì‚° ìˆ˜í–‰
    calculated_weights = {}
    max_cr = 0.0 
    
    # (1) 1ì°¨ ê¸°ì¤€ ê³„ì‚° ('1.' ë˜ëŠ” '1ì°¨'ê°€ í¬í•¨ëœ ê·¸ë£¹)
    main_group_name = next((k for k in groups.keys() if "1." in k or "1ì°¨" in k), None)
    
    if main_group_name:
        items = list(items_in_group[main_group_name])
        w, cr = calculate_ahp(items, groups[main_group_name])
        calculated_weights["MAIN"] = w
        if cr > max_cr: max_cr = cr
    else:
        return None, 9.9 

    # (2) 2ì°¨ ì„¸ë¶€ í•­ëª© ê³„ì‚°
    final_rows = []
    
    for group_name, pairs in groups.items():
        if group_name == main_group_name: continue
        
        # ë¶€ëª¨ ì°¾ê¸°
        parent_name = None
        for m_item in calculated_weights["MAIN"].keys():
            # ê·¸ë£¹ëª…ì— ë©”ì¸ ê¸°ì¤€ ì´ë¦„ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ì˜ˆ: [ë¹„ìš©] ì„¸ë¶€...)
            if m_item in group_name:
                parent_name = m_item
                break
        
        if parent_name:
            items = list(items_in_group[group_name])
            sub_w, sub_cr = calculate_ahp(items, pairs)
            
            if sub_cr > max_cr: max_cr = sub_cr
            
            p_weight = calculated_weights["MAIN"][parent_name]
            for s_item, s_weight in sub_w.items():
                final_rows.append({
                    "1ì°¨ ê¸°ì¤€": parent_name,
                    "1ì°¨ ê°€ì¤‘ì¹˜": p_weight,
                    "2ì°¨ í•­ëª©": s_item,
                    "2ì°¨ ê°€ì¤‘ì¹˜": s_weight,
                    "ì¢…í•© ê°€ì¤‘ì¹˜": p_weight * s_weight
                })

    return final_rows, max_cr

# ==============================================================================
# [UI ë©”ì¸]
# ==============================================================================

if not os.path.exists(DATA_FOLDER):
    os.makedirs(DATA_FOLDER)

files = [f for f in os.listdir(DATA_FOLDER) if f.endswith(".csv")]

if files:
    selected_file = st.selectbox("ğŸ“‚ ë¶„ì„í•  í”„ë¡œì íŠ¸ ì„ íƒ:", files)
    
    if selected_file:
        file_path = os.path.join(DATA_FOLDER, selected_file)
        df = pd.read_csv(file_path)
        
        st.divider()
        st.subheader(f"ğŸ“ˆ í”„ë¡œì íŠ¸ ë¶„ì„: {selected_file.replace('.csv', '').replace('_', ' ')}")
        st.caption(f"ì´ ì‘ë‹µì: {len(df)}ëª…")
        
        if st.button("ğŸ§® ìœ íš¨ì„± ê²€ì‚¬ ë° ë¶„ì„ ì‹¤í–‰", type="primary"):
            
            valid_respondents_data = [] 
            respondent_status = []      
            
            for idx, row in df.iterrows():
                try:
                    res_rows, person_max_cr = process_single_response(row['Raw_Data'])
                    
                    if res_rows is None: continue

                    is_valid = person_max_cr <= 0.1
                    valid_mark = "O" if is_valid else "X"
                    
                    status = {
                        "ì‘ë‹µì": row['Respondent'] if pd.notna(row['Respondent']) else f"ì°¸ì—¬ì {idx+1}",
                        "ì‘ì„±ì‹œê°„": row['Time'],
                        "ìµœëŒ€ CR": round(person_max_cr, 4),
                        "í™œìš© ì—¬ë¶€": valid_mark
                    }
                    respondent_status.append(status)
                    
                    if is_valid:
                        valid_respondents_data.extend(res_rows)
                        
                except Exception as e:
                    continue 

            # 1. ìœ íš¨ì„± ê²€ì‚¬ í‘œ
            st.markdown("### 1ï¸âƒ£ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ (Consistency Check)")
            status_df = pd.DataFrame(respondent_status)
            
            if not status_df.empty:
                def color_validity(val):
                    return 'background-color: #e6fcf5' if val == 'O' else 'background-color: #fff5f5'
                st.dataframe(status_df.style.applymap(color_validity, subset=['í™œìš© ì—¬ë¶€']), use_container_width=True)
            else:
                st.warning("ë¶„ì„í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            # 2. ìµœì¢… ìˆœìœ„ í‘œ
            if valid_respondents_data:
                result_df = pd.DataFrame(valid_respondents_data)
                
                final_df = result_df.groupby(['1ì°¨ ê¸°ì¤€', '2ì°¨ í•­ëª©']).mean(numeric_only=True).reset_index()
                final_df = final_df.sort_values(by='ì¢…í•© ê°€ì¤‘ì¹˜', ascending=False)
                final_df['ìˆœìœ„'] = range(1, len(final_df) + 1)
                
                display_df = final_df[['ìˆœìœ„', '1ì°¨ ê¸°ì¤€', '2ì°¨ í•­ëª©', 'ì¢…í•© ê°€ì¤‘ì¹˜', '1ì°¨ ê°€ì¤‘ì¹˜', '2ì°¨ ê°€ì¤‘ì¹˜']]
                
                st.divider()
                st.markdown("### ğŸ† 2ï¸âƒ£ ìµœì¢… ì¢…í•© ìˆœìœ„ (Global Rank)")
                st.dataframe(
                    display_df.style.format({
                        'ì¢…í•© ê°€ì¤‘ì¹˜': '{:.4f}', '1ì°¨ ê°€ì¤‘ì¹˜': '{:.4f}', '2ì°¨ ê°€ì¤‘ì¹˜': '{:.4f}'
                    }).background_gradient(subset=['ì¢…í•© ê°€ì¤‘ì¹˜'], cmap='Blues'),
                    use_container_width=True
                )
                
                # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
                import io
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    display_df.to_excel(writer, index=False, sheet_name='ì¢…í•©ìˆœìœ„_ê²°ê³¼')
                    status_df.to_excel(writer, index=False, sheet_name='ë°ì´í„°_ìœ íš¨ì„±_ê²€ì‚¬')
                    df.to_excel(writer, index=False, sheet_name='ì›ë³¸_ë°ì´í„°')
                
                st.download_button(
                    label="ğŸ“¥ ì „ì²´ ë¶„ì„ ê²°ê³¼ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                    data=output.getvalue(),
                    file_name=f"Final_{selected_file.replace('.csv', '.xlsx')}",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    type="primary"
                )
            else:
                st.error("ìœ íš¨í•œ ë°ì´í„°(O)ê°€ ì—†ì–´ì„œ ìˆœìœ„ë¥¼ ì‚°ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        with st.expander("ğŸ“‹ ì›ë³¸ ë°ì´í„° í™•ì¸"):
            st.dataframe(df)

else:
    st.info("ğŸ“­ ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
