import streamlit as st
import pandas as pd
import numpy as np
import json
import io
import os
import re

# ==============================================================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==============================================================================
st.set_page_config(page_title="ê²°ê³¼ ë°ì´í„° ì„¼í„°", page_icon="ğŸ“Š", layout="wide")
st.title("ğŸ“Š AHP ê²°ê³¼ ë°ì´í„° ì„¼í„°")

# ë°ì´í„° ì €ì¥ì†Œ ê²½ë¡œ
DATA_FOLDER = "survey_data"
if not os.path.exists(DATA_FOLDER):
    os.makedirs(DATA_FOLDER)

# ==============================================================================
# [í•¨ìˆ˜] ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ (ëŒ€í•­ëª©-ì†Œí•­ëª© ì—°ê²°)
# ==============================================================================
def is_match(main_name, sub_task_name):
    """
    ëŒ€í•­ëª© ì´ë¦„(main_name)ì´ ì†Œí•­ëª© ê·¸ë£¹ ì´ë¦„(sub_task_name)ì— í¬í•¨ë˜ëŠ”ì§€ ìœ ì—°í•˜ê²Œ ê²€ì‚¬
    """
    # ë¹„êµë¥¼ ìœ„í•´ ì–‘ìª½ ë‹¤ ê³µë°± ì œê±°
    clean_main = main_name.replace(" ", "").strip()
    clean_sub = sub_task_name.replace(" ", "").strip()
    
    # 1. ë‹¨ìˆœ í¬í•¨ ê´€ê³„
    if clean_main in clean_sub: 
        return True
    
    # 2. ëŒ€ê´„í˜¸ [] ì•ˆì˜ ë‚´ìš© ì¶”ì¶œ ë¹„êµ
    match = re.search(r'\[(.*?)\]', sub_task_name)
    if match:
        extracted = match.group(1).replace(" ", "").strip()
        if extracted == clean_main:
            return True
            
    return False

# ==============================================================================
# [í•¨ìˆ˜] AHP í•µì‹¬ ì—”ì§„ (ì•ˆì •ì„± ê°•í™”)
# ==============================================================================
def calculate_ahp_metrics(comparisons):
    """
    ì…ë ¥: {"A vs B": 3, ...} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    ì¶œë ¥: (í•­ëª© ë¦¬ìŠ¤íŠ¸, ê°€ì¤‘ì¹˜ ë°°ì—´, CR ê°’)
    """
    # [í•µì‹¬ ìˆ˜ì •] í•­ëª© ì´ë¦„ ì •ê·œí™” (ê³µë°± ì œê±°) -> í•­ëª© ì¤‘ë³µ ë°©ì§€
    # ë°ì´í„°ê°€ "A"ì™€ "A "ë¡œ ë“¤ì–´ì˜¤ë©´ ë‹¤ë¥¸ í•­ëª©ìœ¼ë¡œ ì¸ì‹í•´ í–‰ë ¬ì´ ê¹¨ì§€ëŠ” ë¬¸ì œ í•´ê²°
    
    norm_comps = {}
    items = set()
    
    for pair, val in comparisons.items():
        if " vs " in pair:
            a, b = pair.split(" vs ")
            a = a.strip() # ê³µë°± ì œê±°
            b = b.strip() # ê³µë°± ì œê±°
            items.add(a)
            items.add(b)
            norm_comps[f"{a} vs {b}"] = float(val)
            
    items = sorted(list(items))
    n = len(items)
    item_map = {name: i for i, name in enumerate(items)}

    # í–‰ë ¬ ìƒì„±
    matrix = np.ones((n, n))
    for pair, val in norm_comps.items():
        try:
            a, b = pair.split(" vs ")
            if a in item_map and b in item_map:
                i, j = item_map[a], item_map[b]
                matrix[i][j] = val
                matrix[j][i] = 1 / val
        except: continue

    # ê°€ì¤‘ì¹˜ ê³„ì‚° (Eigenvector Method)
    try:
        eigvals, eigvecs = np.linalg.eig(matrix)
        max_idx = np.argmax(eigvals)
        max_eigval = eigvals[max_idx].real
        weights = eigvecs[:, max_idx].real
        weights = weights / weights.sum()
    except:
        # ì‹¤íŒ¨ ì‹œ ê¸°í•˜í‰ê· ë²• (ì•ˆì •ì )
        weights = np.ones(n)
        for i in range(n):
            weights[i] = np.prod(matrix[i]) ** (1/n)
        weights = weights / weights.sum()
        max_eigval = n

    # CR ê³„ì‚°
    ri_table = {1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45, 10: 1.49}
    ci = (max_eigval - n) / (n - 1) if n > 1 else 0
    ri = ri_table.get(n, 1.49)
    cr = ci / ri if ri != 0 else 0

    return items, weights, cr

# ==============================================================================
# [UI] ì‚¬ì´ë“œë°” ì¸ì¦ ë° ì˜µì…˜
# ==============================================================================
with st.sidebar:
    st.header("ğŸ”‘ ê´€ë¦¬ì ë©”ë‰´")
    user_key = st.text_input("í”„ë¡œì íŠ¸ ë¹„ë°€ë²ˆí˜¸", type="password")
    
    st.divider()
    st.subheader("ğŸ›ï¸ ë¶„ì„ ì˜µì…˜")
    # [í•µì‹¬] ì‚¬ìš©ìê°€ ìœ íš¨ì„± ê¸°ì¤€ì„ ì§ì ‘ ì¡°ì ˆ ê°€ëŠ¥ (ê¸°ë³¸ 0.1 -> 0.2 ë“± ì™„í™” ê°€ëŠ¥)
    cr_threshold = st.slider(
        "CR í—ˆìš© ê¸°ì¤€ (Consistency Threshold)", 
        min_value=0.05, max_value=0.5, value=0.1, step=0.05,
        help="ì´ ê°’ë³´ë‹¤ CRì´ í¬ë©´ 'ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„°'ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. ë°ì´í„°ê°€ ë„ˆë¬´ ë§ì´ ë¹ ì§€ë©´ ì´ ê°’ì„ 0.15~0.2ë¡œ ì˜¬ë ¤ë³´ì„¸ìš”."
    )
    st.caption(f"í˜„ì¬ ê¸°ì¤€: CR â‰¤ {cr_threshold} ì¸ ë°ì´í„°ë§Œ ì‚¬ìš©")

if not user_key:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì— ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

# íŒŒì¼ ìë™ íƒìƒ‰
all_files = [f for f in os.listdir(DATA_FOLDER) if f.endswith(".csv")]
my_files = [f for f in all_files if f.startswith(f"{user_key}_")]

if not my_files:
    st.error("í•´ë‹¹ ë¹„ë°€ë²ˆí˜¸ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

st.sidebar.success(f"ë°ì´í„° {len(my_files)}ê°œ ë°œê²¬")
selected_file = st.selectbox("ğŸ“‚ ë¶„ì„í•  í”„ë¡œì íŠ¸ ì„ íƒ", my_files)

# ==============================================================================
# [ë©”ì¸] ë°ì´í„° ì²˜ë¦¬ ë° ë¦¬í¬íŠ¸
# ==============================================================================
if selected_file:
    file_path = os.path.join(DATA_FOLDER, selected_file)
    raw_df = pd.read_csv(file_path)
    
    st.markdown(f"### ğŸ“„ í”„ë¡œì íŠ¸: **{selected_file.replace(user_key+'_', '').replace('.csv', '')}**")
    
    processed_data = []
    valid_weights = []
    
    progress_bar = st.progress(0)
    
    for idx, row in raw_df.iterrows():
        try:
            survey_dict = json.loads(row['Raw_Data'])
            
            # íƒœìŠ¤í¬ íŒŒì‹± ë¡œì§ (ëŒ€ê´„í˜¸ ì²˜ë¦¬ ê°•í™”)
            tasks = {}
            for k, v in survey_dict.items():
                if "]" in k:
                    # ë§ˆì§€ë§‰ ']' ê¸°ì¤€ ë¶„ë¦¬ (ì¤‘ì²© ëŒ€ê´„í˜¸ ëŒ€ì‘)
                    split_idx = k.rfind("]")
                    task_name = k[1:split_idx] # ë§¨ ì• [ ì œê±°
                    pair = k[split_idx+1:].strip()
                    if task_name not in tasks: tasks[task_name] = {}
                    tasks[task_name][pair] = v
            
            is_valid = True
            resp_weights = {}
            resp_crs = {}
            
            for t_name, comps in tasks.items():
                items, w, cr = calculate_ahp_metrics(comps)
                
                # [í•„í„°ë§] ì„¤ì •í•œ ì„ê³„ê°’ë³´ë‹¤ í¬ë©´ ë¬´íš¨ ì²˜ë¦¬
                if cr > cr_threshold: 
                    is_valid = False
                
                resp_crs[t_name] = cr
                for i, item in enumerate(items):
                    resp_weights[f"{t_name}|{item}"] = w[i]
            
            processed_data.append({
                "Respondent": row['Respondent'],
                "Time": row['Time'],
                "Is_Valid": is_valid,
                "CR_Details": str(resp_crs),
                **resp_weights
            })
            
            if is_valid: valid_weights.append(resp_weights)
                
        except Exception: continue
        progress_bar.progress((idx + 1) / len(raw_df))
    
    progress_bar.empty()
    
    # --------------------------------------------------------------------------
    # 2. ê²°ê³¼ ì§‘ê³„ ë° ê³„ì¸µí™”
    # --------------------------------------------------------------------------
    valid_df = pd.DataFrame(valid_weights)
    full_log_df = pd.DataFrame(processed_data)
    
    # ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° ì¶”ì¶œ
    invalid_rows = pd.DataFrame()
    if not full_log_df.empty:
        invalid_rows = full_log_df[full_log_df['Is_Valid'] == False]

    st.divider()
    c1, c2, c3 = st.columns(3)
    c1.metric("ì´ ì‘ë‹µì", f"{len(processed_data)}ëª…")
    c2.metric("âœ… ìœ íš¨ ë°ì´í„°", f"{len(valid_weights)}ëª…")
    c3.metric(f"âŒ ì œì™¸ë¨ (CR > {cr_threshold})", f"{len(invalid_rows)}ëª…")

    # ìœ íš¨ ë°ì´í„°ê°€ ì—†ì„ ê²½ìš°
    if len(valid_weights) == 0:
        st.warning("âš ï¸ í˜„ì¬ ê¸°ì¤€(CR)ì„ í†µê³¼í•œ ìœ íš¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ê¸°ì¤€ì„ ì™„í™”í•´ë³´ì„¸ìš”.")
        # ë°ì´í„°ê°€ ì—†ì–´ë„ ì—‘ì…€ ë‹¤ìš´ë¡œë“œëŠ” ê°€ëŠ¥í•˜ê²Œ (ì˜¤ë¥˜ ë¶„ì„ ìœ„í•´)
    
    else:
        # ì •ìƒ ë¶„ì„ ë¡œì§
        avg_weights = valid_df.mean()
        
        # êµ¬ì¡° íŒŒì‹±
        tasks_unique = sorted(list(set([k.split("|")[0] for k in avg_weights.index])))
        main_task = tasks_unique[0]
        sub_tasks = tasks_unique[1:]
        
        final_rows = []
        main_items_keys = [k for k in avg_weights.index if k.startswith(main_task)]
        main_items_data = []
        for k in main_items_keys:
            main_items_data.append({"name": k.split("|")[1], "weight": avg_weights[k]})
        
        # ëŒ€í•­ëª© ê°€ì¤‘ì¹˜ ìˆœ ì •ë ¬
        main_items_data.sort(key=lambda x: x['weight'], reverse=True)

        for m_item in main_items_data:
            m_name = m_item['name']
            m_weight = m_item['weight']
            
            matching_sub_task = None
            for st_name in sub_tasks:
                if is_match(m_name, st_name):
                    matching_sub_task = st_name
                    break
            
            if matching_sub_task:
                sub_keys = [k for k in avg_weights.index if k.startswith(matching_sub_task)]
                temp_subs = []
                for s_key in sub_keys:
                    s_name = s_key.split("|")[1]
                    s_weight = avg_weights[s_key]
                    global_w = m_weight * s_weight
                    temp_subs.append({
                        "s_name": s_name, 
                        "s_weight": s_weight, 
                        "global_w": global_w
                    })
                
                temp_subs.sort(key=lambda x: x['global_w'], reverse=True)
                
                for i, sub in enumerate(temp_subs):
                    final_rows.append({
                        "ëŒ€í•­ëª©ëª…": m_name if i == 0 else "",      
                        "ëŒ€í•­ëª© ê°€ì¤‘ì¹˜": m_weight if i == 0 else None, 
                        "ì†Œí•­ëª©ëª…": sub['s_name'],
                        "ì†Œí•­ëª© ê°€ì¤‘ì¹˜": sub['s_weight'],
                        "ì¢…í•© ê°€ì¤‘ì¹˜": sub['global_w'],
                        "Raw_Global": sub['global_w']
                    })
            else:
                final_rows.append({
                    "ëŒ€í•­ëª©ëª…": m_name,
                    "ëŒ€í•­ëª© ê°€ì¤‘ì¹˜": m_weight,
                    "ì†Œí•­ëª©ëª…": "-",
                    "ì†Œí•­ëª© ê°€ì¤‘ì¹˜": None,
                    "ì¢…í•© ê°€ì¤‘ì¹˜": m_weight,
                    "Raw_Global": m_weight
                })

        report_df = pd.DataFrame(final_rows)
        
        # ìˆœìœ„ ê³„ì‚° (KeyError ë°©ì§€)
        report_df['ìˆœìœ„'] = np.nan
        rank_mask = report_df['ì†Œí•­ëª©ëª…'] != "-"
        if rank_mask.any():
            report_df.loc[rank_mask, 'ìˆœìœ„'] = report_df.loc[rank_mask, 'Raw_Global'].rank(ascending=False).astype(int)
        
        # ----------------------------------------------------------------------
        # 3. í™”ë©´ ì¶œë ¥
        # ----------------------------------------------------------------------
        st.subheader("ğŸ† ìµœì¢… ê°€ì¤‘ì¹˜ ë° ìˆœìœ„ ë¦¬í¬íŠ¸")
        
        display_cols = ["ëŒ€í•­ëª©ëª…", "ëŒ€í•­ëª© ê°€ì¤‘ì¹˜", "ì†Œí•­ëª©ëª…", "ì†Œí•­ëª© ê°€ì¤‘ì¹˜", "ì¢…í•© ê°€ì¤‘ì¹˜", "ìˆœìœ„"]
        display_df = report_df[display_cols].copy()
        
        def fmt(x): return f"{x:.4f}" if pd.notnull(x) and x != "" else ""
        
        display_df["ëŒ€í•­ëª© ê°€ì¤‘ì¹˜"] = display_df["ëŒ€í•­ëª© ê°€ì¤‘ì¹˜"].apply(fmt)
        display_df["ì†Œí•­ëª© ê°€ì¤‘ì¹˜"] = display_df["ì†Œí•­ëª© ê°€ì¤‘ì¹˜"].apply(fmt)
        display_df["ì¢…í•© ê°€ì¤‘ì¹˜"] = display_df["ì¢…í•© ê°€ì¤‘ì¹˜"].apply(fmt)
        display_df["ìˆœìœ„"] = display_df["ìˆœìœ„"].apply(lambda x: f"{int(x)}ìœ„" if pd.notnull(x) else "")
        
        st.dataframe(display_df, use_container_width=True, hide_index=True)

    # --------------------------------------------------------------------------
    # 4. Excel ë‹¤ìš´ë¡œë“œ (ìœ íš¨ ë°ì´í„° ì—†ì–´ë„ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥)
    # --------------------------------------------------------------------------
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        if len(valid_weights) > 0:
            display_df.to_excel(writer, sheet_name='1_ìµœì¢…_ë¶„ì„_ê²°ê³¼', index=False)
        else:
            # ë¹ˆ ì‹œíŠ¸ ìƒì„± (ì—ëŸ¬ ë°©ì§€)
            pd.DataFrame(["ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"]).to_excel(writer, sheet_name='1_ê²°ê³¼_ì—†ìŒ')
            
        raw_df.to_excel(writer, sheet_name='2_ì „ì²´_ì›ë³¸_ë°ì´í„°', index=False)
        
        if not invalid_rows.empty:
            # ë³´ê¸° ì¢‹ê²Œ ì»¬ëŸ¼ ì •ë¦¬
            inv_export = invalid_rows[["Respondent", "Time", "CR_Details"]].copy()
            inv_export.to_excel(writer, sheet_name='3_ì œì™¸ëœ_ë°ì´í„°_ìƒì„¸', index=False)
            
    st.download_button(
        label="ğŸ“¥ ì—‘ì…€ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (ìœ íš¨/ë¬´íš¨ í¬í•¨)",
        data=output.getvalue(),
        file_name=f"AHP_Report_{selected_file.replace('.csv','')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        type="primary"
    )

    # --------------------------------------------------------------------------
    # 5. ì‚­ì œ ê¸°ëŠ¥
    # --------------------------------------------------------------------------
    st.divider()
    with st.expander("ğŸ—‘ï¸ ë°ì´í„° ì‚­ì œ"):
        if st.button("í˜„ì¬ ë°ì´í„° ì˜êµ¬ ì‚­ì œ"):
            os.remove(file_path)
            st.success("ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()
