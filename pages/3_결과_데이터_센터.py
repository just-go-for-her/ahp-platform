import streamlit as st
import pandas as pd
import numpy as np
import json
import io
import os
import re
import requests # [ì¶”ê°€] êµ¬ê¸€ ì‹œíŠ¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ í•„ìš”

# ==============================================================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==============================================================================
st.set_page_config(page_title="ê²°ê³¼ ë°ì´í„° ì„¼í„°", page_icon="ğŸ“Š", layout="wide")
st.title("ğŸ“Š AHP ê²°ê³¼ ë°ì´í„° ì„¼í„°")

# ë°ì´í„° ì €ì¥ì†Œ ê²½ë¡œ
DATA_FOLDER = "survey_data"
if not os.path.exists(DATA_FOLDER):
    os.makedirs(DATA_FOLDER)

# [ì¶”ê°€] êµ¬ê¸€ ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (ê¸°ëŠ¥ ì¶”ê°€)
def load_from_google_cloud(user_key):
    """
    êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ëœ ì „ì²´ ë°ì´í„° ì¤‘ í˜„ì¬ ì‚¬ìš©ìì˜ ë¹„ë°€ë²ˆí˜¸(user_key)ì™€ ì¼ì¹˜í•˜ëŠ” ê²ƒë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    # ì‚¬ìš©ìë‹˜ì˜ êµ¬ê¸€ Apps Script URLì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”. (doGet í•¨ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•¨)
    WEBAPP_URL = "https://script.google.com/macros/s/AKfycbw-c1Cf71eSMFaouFhN_YziqOl05KBqZzt4-qOXFwkbFBUQrS4ADMozoIswYdAsQiIIOQ/exec"
    try:
        # ë¹„ë°€ë²ˆí˜¸ë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë³´ë‚´ì„œ í•´ë‹¹ ë°ì´í„°ë§Œ ì‘ë‹µë°›ìŒ
        response = requests.get(WEBAPP_URL, params={"user_key": user_key}, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if data:
                # êµ¬ê¸€ ì‹œíŠ¸ ë°ì´í„°ë¥¼ ê¸°ì¡´ CSV êµ¬ì¡°ì™€ ë™ì¼í•œ DataFrameìœ¼ë¡œ ë³€í™˜
                df = pd.DataFrame(data)
                # ì»¬ëŸ¼ëª… ë§¤ì¹­ (Time, Respondent, Raw_Data)
                return df
    except:
        pass
    return pd.DataFrame()

# ==============================================================================
# [í•¨ìˆ˜] ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ & í–‰ë ¬ ë³´ì • ì—”ì§„ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# ==============================================================================
def is_match(main_name, sub_task_name):
    """ëŒ€í•­ëª© ì´ë¦„ì´ ì†Œí•­ëª© ê·¸ë£¹ ì´ë¦„ì— í¬í•¨ë˜ëŠ”ì§€ ê²€ì‚¬"""
    clean_main = main_name.replace(" ", "").strip()
    clean_sub = sub_task_name.replace(" ", "").strip()
    if clean_main in clean_sub: return True
    match = re.search(r'\[(.*?)\]', sub_task_name)
    if match:
        extracted = match.group(1).replace(" ", "").strip()
        if extracted == clean_main: return True
    return False

def get_cr(matrix, n):
    """í–‰ë ¬ì˜ CRê°’ ê³„ì‚°"""
    try:
        eigvals, _ = np.linalg.eig(matrix)
        max_eigval = np.max(eigvals.real)
        ci = (max_eigval - n) / (n - 1) if n > 1 else 0
        ri_table = {1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45}
        ri = ri_table.get(n, 1.49)
        return ci / ri if ri != 0 else 0
    except:
        return 1.0

def calibrate_matrix(matrix, target_cr=0.1, max_iter=50, max_scale=5.0):
    """5ì  ì²™ë„ ì œí•œ ë³´ì • ì•Œê³ ë¦¬ì¦˜"""
    n = matrix.shape[0]
    curr_matrix = matrix.copy()
    
    for _ in range(max_iter):
        cr = get_cr(curr_matrix, n)
        if cr <= target_cr: break
            
        eigvals, eigvecs = np.linalg.eig(curr_matrix)
        max_idx = np.argmax(eigvals)
        w = eigvecs[:, max_idx].real
        w = w / w.sum()
        
        perfect_matrix = np.zeros((n, n))
        for i in range(n):
            for j in range(n):
                if w[j] != 0:
                    val = w[i] / w[j]
                    if val > max_scale: val = max_scale
                    if val < 1/max_scale: val = 1/max_scale
                    perfect_matrix[i][j] = val
                else:
                    perfect_matrix[i][j] = 1.0
                    
        alpha = 0.8 
        curr_matrix = alpha * curr_matrix + (1 - alpha) * perfect_matrix
        
        for i in range(n):
            for j in range(n):
                if curr_matrix[i][j] > max_scale: curr_matrix[i][j] = max_scale
                if curr_matrix[i][j] < 1/max_scale: curr_matrix[i][j] = 1/max_scale
        
        for i in range(n):
            curr_matrix[i][i] = 1.0
            for j in range(i+1, n):
                curr_matrix[j][i] = 1.0 / curr_matrix[i][j]
                
    return curr_matrix

def calculate_ahp_metrics(comparisons, do_calibration=False, cr_limit=0.1, max_scale=5.0):
    norm_comps = {}
    items = set()
    for pair, val in comparisons.items():
        if " vs " in pair:
            a, b = pair.split(" vs ")
            a, b = a.strip(), b.strip()
            items.add(a); items.add(b)
            norm_comps[f"{a} vs {b}"] = float(val)
    items = sorted(list(items))
    n = len(items)
    item_map = {name: i for i, name in enumerate(items)}

    matrix = np.ones((n, n))
    for pair, val in norm_comps.items():
        try:
            a, b = pair.split(" vs ")
            if a in item_map and b in item_map:
                i, j = item_map[a], item_map[b]
                matrix[i][j] = val
                matrix[j][i] = 1 / val
        except: continue

    original_cr = get_cr(matrix, n)
    final_cr = original_cr
    was_calibrated = False

    if original_cr > cr_limit and do_calibration:
        matrix = calibrate_matrix(matrix, target_cr=cr_limit, max_scale=max_scale)
        final_cr = get_cr(matrix, n)
        was_calibrated = True

    try:
        eigvals, eigvecs = np.linalg.eig(matrix)
        max_idx = np.argmax(eigvals)
        weights = eigvecs[:, max_idx].real
        weights = weights / weights.sum()
    except:
        weights = np.ones(n) / n

    return items, weights, final_cr, was_calibrated

# ==============================================================================
# [UI] ì‚¬ì´ë“œë°” (ê¸°ì¡´ ìœ ì§€ + êµ¬ê¸€ ë°ì´í„° ë¡œë“œ ë²„íŠ¼ ì¶”ê°€)
# ==============================================================================
with st.sidebar:
    st.header("ğŸ”‘ ê´€ë¦¬ì ë©”ë‰´")
    user_key = st.text_input("í”„ë¡œì íŠ¸ ë¹„ë°€ë²ˆí˜¸", type="password")
    
    st.divider()
    st.subheader("ğŸ›ï¸ ë¶„ì„ ì˜µì…˜")
    auto_calibrate = st.checkbox("âœ¨ ë°ì´í„° ìë™ ë³´ì •", value=True)
    cr_threshold = st.slider("CR í—ˆìš© ê¸°ì¤€", 0.05, 0.5, 0.1, 0.05)
    max_scale_val = st.number_input("ìµœëŒ€ ë°°ìˆ˜ ì œí•œ", value=5.0, min_value=3.0, max_value=9.0)

if not user_key:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì— ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

# [ì¶”ê°€/ìˆ˜ì •] ê¸°ì¡´ ë¡œì»¬ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
all_files = [f for f in os.listdir(DATA_FOLDER) if f.endswith(".csv")]
my_files = [f for f in all_files if f.startswith(f"{user_key}_")]

# [ì¶”ê°€] êµ¬ê¸€ í´ë¼ìš°ë“œì—ì„œ ë°±ì—… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë²„íŠ¼
st.sidebar.divider()
if st.sidebar.button("â˜ï¸ êµ¬ê¸€ í´ë¼ìš°ë“œì—ì„œ ë³µêµ¬"):
    cloud_df = load_from_google_cloud(user_key)
    if not cloud_df.empty:
        st.session_state['cloud_data'] = cloud_df
        st.success("âœ… í´ë¼ìš°ë“œ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    else:
        st.error("í´ë¼ìš°ë“œì— ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ==============================================================================
# [ë©”ì¸] ë°ì´í„° ë¡œë“œ ë¡œì§ (ë¡œì»¬ ìš°ì„ , í´ë¼ìš°ë“œ ë³´ì¡°)
# ==============================================================================
raw_df = pd.DataFrame()

if my_files:
    selected_file = st.selectbox("ğŸ“‚ ë¡œì»¬ í”„ë¡œì íŠ¸ ì„ íƒ", my_files)
    if selected_file:
        file_path = os.path.join(DATA_FOLDER, selected_file)
        # ê¸°ì¡´ ì½”ë“œ
# raw_df = pd.read_csv(file_path)

# ìˆ˜ì • ì½”ë“œ (í•œê¸€ ì¸ì½”ë”© ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ encoding='utf-8-sig' ì¶”ê°€)
try:
    raw_df = pd.read_csv(file_path, encoding='utf-8-sig')
except UnicodeDecodeError:
    # ë§Œì•½ ìœ„ ë°©ë²•ìœ¼ë¡œ ì•ˆ ë  ê²½ìš° í•œêµ­ì–´ ì „ìš© ì¸ì½”ë”© ì‹œë„
    raw_df = pd.read_csv(file_path, encoding='cp949')
        st.markdown(f"### ğŸ“„ ë¡œì»¬ í”„ë¡œì íŠ¸: **{selected_file.replace(user_key+'_', '').replace('.csv', '')}**")
elif 'cloud_data' in st.session_state:
    raw_df = st.session_state['cloud_data']
    st.markdown(f"### ğŸ“„ í´ë¼ìš°ë“œ ë³µêµ¬ ë°ì´í„° (ì´ {len(raw_df)}ê±´)")
else:
    st.error("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬ íŒŒì¼ì´ ì‚¬ë¼ì¡Œë‹¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ [â˜ï¸ êµ¬ê¸€ í´ë¼ìš°ë“œì—ì„œ ë³µêµ¬]ë¥¼ ëˆŒëŸ¬ë³´ì„¸ìš”.")
    st.stop()

# --- ì´í›„ ëª¨ë“  AHP ë¶„ì„ ë¡œì§ (processed_data ìƒì„± ë“±)ì€ ê¸°ì¡´ ì½”ë“œì™€ 100% ë™ì¼í•˜ê²Œ ì‹¤í–‰ë¨ ---
if not raw_df.empty:
    processed_data = []
    valid_weights = []
    task_crs = {} # íƒœìŠ¤í¬ë³„ í‰ê·  CR ì €ì¥ìš©
    
    calibrated_count = 0
    progress_bar = st.progress(0)
    
    for idx, row in raw_df.iterrows():
        try:
            survey_dict = json.loads(row['Raw_Data'])
            tasks = {}
            for k, v in survey_dict.items():
                if "]" in k:
                    split_idx = k.rfind("]")
                    task_name = k[1:split_idx]
                    pair = k[split_idx+1:].strip()
                    if task_name not in tasks: tasks[task_name] = {}
                    tasks[task_name][pair] = v
            
            is_valid = True
            resp_weights = {}
            resp_crs = {}
            is_resp_calibrated = False
            
            for t_name, comps in tasks.items():
                items, w, cr, calib = calculate_ahp_metrics(
                    comps, 
                    do_calibration=auto_calibrate, 
                    cr_limit=cr_threshold,
                    max_scale=max_scale_val
                )
                
                if cr > cr_threshold: is_valid = False
                if calib: is_resp_calibrated = True
                
                resp_crs[t_name] = cr
                for i, item in enumerate(items):
                    resp_weights[f"{t_name}|{item}"] = w[i]
                
                if is_valid:
                    if t_name not in task_crs: task_crs[t_name] = []
                    task_crs[t_name].append(cr)
            
            status = "Valid"
            if not is_valid: status = "Invalid"
            elif is_resp_calibrated: status = "Calibrated"
            
            if is_resp_calibrated and is_valid: calibrated_count += 1
            
            processed_data.append({
                "Respondent": row['Respondent'],
                "Time": row['Time'],
                "Status": status,
                "Is_Valid": is_valid,
                "CR_Details": str(resp_crs),
                **resp_weights
            })
            
            if is_valid: valid_weights.append(resp_weights)
        except Exception: continue
        progress_bar.progress((idx + 1) / len(raw_df))
    
    progress_bar.empty()
    
    # ... (ì´í•˜ ìœ íš¨ì„± í†µê³„, ê°€ì¤‘ì¹˜ í‰ê·  ê³„ì‚°, ë¦¬í¬íŠ¸ ì¶œë ¥ ë° ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë¡œì§ì€ ì‚¬ìš©ìë‹˜ì˜ ê¸°ì¡´ ì½”ë“œì™€ ì™„ë²½íˆ ë™ì¼í•¨) ...
    # (ì½”ë“œ ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ìƒëµí•˜ì§€ë§Œ, ì‹¤ì œ ì ìš© ì‹œì—ëŠ” ê¸°ì¡´ ë¦¬í¬íŠ¸ ì¶œë ¥ ì½”ë“œë¥¼ ì´ ì•„ë˜ì— ê·¸ëŒ€ë¡œ ë¶™ì´ì‹œë©´ ë©ë‹ˆë‹¤.)
    
    valid_df = pd.DataFrame(valid_weights)
    full_log_df = pd.DataFrame(processed_data)
    
    st.divider()
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì´ ì‘ë‹µ", f"{len(processed_data)}ëª…")
    c2.metric("âœ… ìœ íš¨ ë°ì´í„°", f"{len(valid_weights)}ëª…")
    c3.metric("âœ¨ 5ì ì²™ë„ ë³´ì •", f"{calibrated_count}ëª…")
    c4.metric("âŒ ì œì™¸ë¨", f"{len(processed_data) - len(valid_weights)}ëª…")

    if len(valid_weights) == 0:
        st.error("ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    avg_weights = valid_df.mean()
    tasks_unique = sorted(list(set([k.split("|")[0] for k in avg_weights.index])))
    if not tasks_unique: st.stop()
        
    main_task = tasks_unique[0]
    sub_tasks = tasks_unique[1:]
    
    final_rows = []
    
    def get_avg_cr(task_name):
        if task_name in task_crs and len(task_crs[task_name]) > 0:
            return np.mean(task_crs[task_name])
        return 0.0

    main_keys = [k for k in avg_weights.index if k.startswith(main_task)]
    main_items_data = []
    for k in main_keys:
        main_items_data.append({"name": k.split("|")[1], "weight": avg_weights[k]})
    main_items_data.sort(key=lambda x: x['weight'], reverse=True)

    main_cr = get_avg_cr(main_task)

    for m_item in main_items_data:
        m_name = m_item['name']
        m_weight = m_item['weight']
        matching_sub_task = None
        for st_name in sub_tasks:
            if is_match(m_name, st_name):
                matching_sub_task = st_name
                break
        
        if matching_sub_task:
            sub_cr = get_avg_cr(matching_sub_task)
            sub_keys = [k for k in avg_weights.index if k.startswith(matching_sub_task)]
            temp_subs = []
            for s_key in sub_keys:
                s_name = s_key.split("|")[1]
                s_weight = avg_weights[s_key]
                global_w = m_weight * s_weight
                temp_subs.append({"s_name": s_name, "s_weight": s_weight, "global_w": global_w})
            temp_subs.sort(key=lambda x: x['global_w'], reverse=True)
            for i, sub in enumerate(temp_subs):
                final_rows.append({
                    "ëŒ€í•­ëª©ëª…": m_name if i == 0 else "",      
                    "ëŒ€í•­ëª© ê°€ì¤‘ì¹˜": m_weight if i == 0 else None, 
                    "ì†Œí•­ëª©ëª…": sub['s_name'],
                    "ì†Œí•­ëª© ê°€ì¤‘ì¹˜": sub['s_weight'],
                    "ì¢…í•© ê°€ì¤‘ì¹˜": sub['global_w'],
                    "ìˆœìœ„": 0,
                    "ê·¸ë£¹ CR": sub_cr,
                    "is_main_cr": False
                })
        else:
            final_rows.append({
                "ëŒ€í•­ëª©ëª…": m_name, "ëŒ€í•­ëª© ê°€ì¤‘ì¹˜": m_weight, 
                "ì†Œí•­ëª©ëª…": "-", "ì†Œí•­ëª© ê°€ì¤‘ì¹˜": None,
                "ì¢…í•© ê°€ì¤‘ì¹˜": m_weight, "ìˆœìœ„": 0,
                "ê·¸ë£¹ CR": main_cr,
                "is_main_cr": True
            })

    report_df = pd.DataFrame(final_rows)
    report_df['ìˆœìœ„'] = np.nan
    rank_mask = report_df['ì†Œí•­ëª©ëª…'] != "-"
    if rank_mask.any():
        report_df.loc[rank_mask, 'ìˆœìœ„'] = report_df.loc[rank_mask, 'ì¢…í•© ê°€ì¤‘ì¹˜'].rank(ascending=False).astype(int)
    
    st.subheader("ğŸ† ìµœì¢… ê°€ì¤‘ì¹˜ ë° ìˆœìœ„ ë¦¬í¬íŠ¸")
    st.info(f"ğŸ“Œ **1ë‹¨ê³„(ëŒ€í•­ëª©) í‰ê·  CR:** {main_cr:.4f}")
    
    display_cols = ["ëŒ€í•­ëª©ëª…", "ëŒ€í•­ëª© ê°€ì¤‘ì¹˜", "ì†Œí•­ëª©ëª…", "ì†Œí•­ëª© ê°€ì¤‘ì¹˜", "ì¢…í•© ê°€ì¤‘ì¹˜", "ìˆœìœ„", "ê·¸ë£¹ CR"]
    display_df = report_df[display_cols].copy()
    
    def fmt(x): return f"{x:.4f}" if pd.notnull(x) and x != "" else ""
    for c in ["ëŒ€í•­ëª© ê°€ì¤‘ì¹˜", "ì†Œí•­ëª© ê°€ì¤‘ì¹˜", "ì¢…í•© ê°€ì¤‘ì¹˜", "ê·¸ë£¹ CR"]:
        display_df[c] = display_df[c].apply(fmt)
        
    display_df["ìˆœìœ„"] = display_df["ìˆœìœ„"].apply(lambda x: f"{int(x)}ìœ„" if pd.notnull(x) else "")
    st.dataframe(display_df, use_container_width=True, hide_index=True)
    
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        display_df.to_excel(writer, sheet_name='1_ìµœì¢…_ë¶„ì„_ê²°ê³¼', index=False)
        raw_df.to_excel(writer, sheet_name='2_ì „ì²´_ì›ë³¸_ë°ì´í„°', index=False)
        full_log_df[["Respondent", "Time", "Status", "CR_Details"]].to_excel(writer, sheet_name='3_ë°ì´í„°_ìƒíƒœ_ë¡œê·¸', index=False)
            
    st.download_button("ğŸ“¥ ì—‘ì…€ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ", output.getvalue(), f"Report_Analysis.xlsx", "primary")
