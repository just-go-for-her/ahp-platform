import streamlit as st
import pandas as pd
import json
import os
import re
import numpy as np
import io

# --------------------------------------------------------------------------
# 1. í˜ì´ì§€ ì„¤ì •
# --------------------------------------------------------------------------
st.set_page_config(page_title="ê²°ê³¼ ë°ì´í„° ì„¼í„°", page_icon="ğŸ“Š", layout="wide")

st.title("ğŸ” ê²°ê³¼ ë°ì´í„° ì„¼í„° (Private)")

DATA_FOLDER = "survey_data"
if not os.path.exists(DATA_FOLDER):
    os.makedirs(DATA_FOLDER)

# --------------------------------------------------------------------------
# 2. AHP ê³„ì‚° ì—”ì§„
# --------------------------------------------------------------------------
RI_TABLE = {1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45, 10: 1.49}

def saaty_scale(val):
    val = int(val)
    if val == 0: return 1
    elif val < 0: return 1 / (abs(val) + 1)
    else: return val + 1

def calculate_ahp(items, pairs_data):
    n = len(items)
    if n == 0: return {}, 0
    
    matrix = np.ones((n, n))
    item_map = {name: i for i, name in enumerate(items)}

    for key, val in pairs_data.items():
        if " vs " in key:
            parts = key.split(" vs ")
            item_a, item_b = parts[0].strip(), parts[1].strip()
            if item_a in item_map and item_b in item_map:
                idx_a, idx_b = item_map[item_a], item_map[item_b]
                scale_val = saaty_scale(val)
                matrix[idx_a][idx_b] = scale_val
                matrix[idx_b][idx_a] = 1 / scale_val

    geo_means = []
    for i in range(n):
        row_prod = np.prod(matrix[i])
        geo_means.append(row_prod ** (1/n))
    
    total_sum = sum(geo_means)
    weights = [gm / total_sum for gm in geo_means]
    weights_dict = {items[i]: w for i, w in enumerate(weights)}

    if n <= 2: cr = 0.0
    else:
        lambda_max = 0
        for i in range(n):
            col_sum = np.sum(matrix[:, i])
            lambda_max += col_sum * weights[i]
        ci = (lambda_max - n) / (n - 1)
        ri = RI_TABLE.get(n, 1.49)
        cr = ci / ri if ri != 0 else 0

    return weights_dict, cr

def process_single_response(raw_json):
    try:
        data = json.loads(raw_json)
    except:
        return None, 9.9 

    groups, items_in_group = {}, {}
    for full_key, val in data.items():
        match = re.match(r"\[(.*?)\](.*)", full_key)
        if match:
            group_name, pair_key = match.group(1), match.group(2).strip()
            if group_name not in groups: 
                groups[group_name] = {}
                items_in_group[group_name] = set()
            groups[group_name][pair_key] = val
            if " vs " in pair_key:
                a, b = pair_key.split(" vs ")
                items_in_group[group_name].add(a.strip())
                items_in_group[group_name].add(b.strip())

    calculated_weights = {}
    max_cr = 0.0 
    
    main_group_name = next((k for k in groups.keys() if "1." in k or "ê¸°ì¤€" in k), None)
    
    if main_group_name:
        items = list(items_in_group[main_group_name])
        w, cr = calculate_ahp(items, groups[main_group_name])
        calculated_weights["MAIN"] = w
        if cr > max_cr: max_cr = cr
    else:
        return None, 9.9 

    final_rows = []
    
    # [ì¶”ê°€] ê°œì¸ë³„ ê°€ì¤‘ì¹˜ë¥¼ í•œ ì¤„ë¡œ í¼ì¹˜ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    flat_personal_data = {} 
    
    for group_name, pairs in groups.items():
        if group_name == main_group_name: continue
        
        parent_name = None
        for m_item in calculated_weights["MAIN"].keys():
            if m_item in group_name:
                parent_name = m_item
                break
        
        if parent_name:
            items = list(items_in_group[group_name])
            sub_w, sub_cr = calculate_ahp(items, pairs)
            if sub_cr > max_cr: max_cr = sub_cr
            
            p_weight = calculated_weights["MAIN"][parent_name]
            for s_item, s_weight in sub_w.items():
                final_weight = p_weight * s_weight
                final_rows.append({
                    "1ì°¨ ê¸°ì¤€": parent_name,
                    "1ì°¨ ê°€ì¤‘ì¹˜": p_weight,
                    "2ì°¨ í•­ëª©": s_item,
                    "2ì°¨ ê°€ì¤‘ì¹˜": s_weight,
                    "ì¢…í•© ê°€ì¤‘ì¹˜": final_weight
                })
                # ì—‘ì…€ìš© ê°œì¸ ë°ì´í„° ì €ì¥ (ì˜ˆ: "ë§› > ë§¤ìš´ë§›")
                col_name = f"{parent_name} > {s_item}"
                flat_personal_data[col_name] = final_weight

    return final_rows, max_cr, flat_personal_data

# --------------------------------------------------------------------------
# 3. ë©”ì¸ UI
# --------------------------------------------------------------------------
with st.sidebar:
    st.header("ğŸ”‘ ì ‘ì† ì¸ì¦")
    user_key = st.text_input("í”„ë¡œì íŠ¸ ë¹„ë°€ë²ˆí˜¸(Key)", type="password")

if not user_key:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì— **í”„ë¡œì íŠ¸ ë¹„ë°€ë²ˆí˜¸**ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

all_files = [f for f in os.listdir(DATA_FOLDER) if f.endswith(".csv")]
my_files = [f for f in all_files if f.startswith(f"{user_key}_")]

if not my_files:
    st.error(f"ë¹„ë°€ë²ˆí˜¸ '{user_key}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

st.success(f"ì¸ì¦ ì„±ê³µ! í”„ë¡œì íŠ¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
selected_file = st.selectbox("ğŸ“‚ ë¶„ì„í•  ë°ì´í„° ì„ íƒ:", my_files)

if selected_file:
    file_path = os.path.join(DATA_FOLDER, selected_file)
    df = pd.read_csv(file_path)
    
    st.divider()
    display_name = selected_file.replace(f"{user_key}_", "").replace(".csv", "").replace("_", " ")
    st.subheader(f"ğŸ“ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ: {display_name}")
    st.caption(f"ì´ ì‘ë‹µ ìˆ˜: {len(df)}ëª…")
    
    if st.button("ğŸ§® ë¶„ì„ ì‹¤í–‰ (ë¦¬í¬íŠ¸ ìƒì„±)", type="primary"):
        
        valid_data_rows = []    # ì§‘ë‹¨ ë¶„ì„ìš© (ì„¸ë¡œë¡œ ê¸´ ë°ì´í„°)
        status_list = []        # ì‘ë‹µ í˜„í™©ìš©
        personal_analysis_list = [] # ê°œì¸ë³„ ìƒì„¸ ë¶„ì„ìš© (ê°€ë¡œë¡œ ë„“ì€ ë°ì´í„°)
        
        # 1. ë°˜ë³µë¬¸ìœ¼ë¡œ ë¶„ì„ ìˆ˜í–‰
        for idx, row in df.iterrows():
            try:
                # í•¨ìˆ˜ì—ì„œ 3ê°€ì§€ë¥¼ ë¦¬í„´ë°›ìŒ (ê²°ê³¼í–‰, CR, ê°œì¸ë³„í¼ì¹œë°ì´í„°)
                res_rows, person_cr, flat_data = process_single_response(row['Raw_Data'])
                
                if res_rows is None: continue

                is_valid = person_cr <= 0.1
                status = {
                    "ìˆœë²ˆ": idx + 1,
                    "ì‘ë‹µì": row.get('Respondent', 'ìµëª…'),
                    "ì‘ì„±ì‹œê°„": row['Time'],
                    "ì¼ê´€ì„±ì§€ìˆ˜(CR)": round(person_cr, 4),
                    "ìœ íš¨íŒì •": "O" if is_valid else "X"
                }
                status_list.append(status)
                
                if is_valid:
                    valid_data_rows.extend(res_rows)
                    
                    # [í•µì‹¬] ê°œì¸ë³„ ìƒì„¸ ë°ì´í„° ë§Œë“¤ê¸°
                    # ê¸°ë³¸ ì •ë³´(ëˆ„ê°€, ì–¸ì œ) + ê³„ì‚°ëœ ê°€ì¤‘ì¹˜ë“¤
                    personal_info = {
                        "ì‘ë‹µì": row.get('Respondent', 'ìµëª…'),
                        "ì‘ì„±ì‹œê°„": row['Time'],
                        "ì¼ê´€ì„±ì§€ìˆ˜(CR)": round(person_cr, 4)
                    }
                    # ë‘ ë”•ì…”ë„ˆë¦¬ í•©ì¹˜ê¸°
                    personal_info.update(flat_data)
                    personal_analysis_list.append(personal_info)
                    
            except Exception as e:
                continue 

        # -------------------------------------------------------
        # [í™”ë©´ ì¶œë ¥]
        # -------------------------------------------------------
        
        # 1. ìœ íš¨ì„± ê²€ì‚¬ í‘œ
        st.markdown("### 1ï¸âƒ£ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦")
        status_df = pd.DataFrame(status_list)
        if not status_df.empty:
            def color_val(val):
                return 'background-color: #e6fcf5' if val == 'O' else 'background-color: #fff5f5'
            st.dataframe(status_df.style.applymap(color_val, subset=['ìœ íš¨íŒì •']), use_container_width=True)
            valid_count = len(status_df[status_df['ìœ íš¨íŒì •'] == 'O'])
            st.info(f"ì´ {len(status_df)}ëª… ì¤‘ **{valid_count}ëª…(O)**ì˜ ë°ì´í„°ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
        
        # 2. ì¢…í•© ìˆœìœ„ (ì§‘ë‹¨)
        if valid_data_rows:
            res_df = pd.DataFrame(valid_data_rows)
            final_df = res_df.groupby(['1ì°¨ ê¸°ì¤€', '2ì°¨ í•­ëª©']).mean(numeric_only=True).reset_index()
            final_df = final_df.sort_values(by='ì¢…í•© ê°€ì¤‘ì¹˜', ascending=False)
            final_df['ìˆœìœ„'] = range(1, len(final_df) + 1)
            
            disp_df = final_df[['ìˆœìœ„', '1ì°¨ ê¸°ì¤€', '2ì°¨ í•­ëª©', 'ì¢…í•© ê°€ì¤‘ì¹˜']]
            
            st.divider()
            st.markdown("### ğŸ† 2ï¸âƒ£ ìµœì¢… ì¢…í•© ìˆœìœ„ (ì§‘ë‹¨ í‰ê· )")
            st.dataframe(disp_df.style.background_gradient(subset=['ì¢…í•© ê°€ì¤‘ì¹˜'], cmap='Blues'), use_container_width=True)

            # -------------------------------------------------------
            # [ì—‘ì…€ ë‹¤ìš´ë¡œë“œ] ì‹œíŠ¸ ìª¼ê°œê¸° ê¸°ìˆ  ì ìš©
            # -------------------------------------------------------
            st.divider()
            st.markdown("### ğŸ“¥ ìƒì„¸ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ")
            
            # ê°œì¸ë³„ ìƒì„¸ ë°ì´í„° í”„ë ˆì„ ìƒì„±
            personal_df = pd.DataFrame(personal_analysis_list)
            
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # ì‹œíŠ¸ 1: ì¢…í•© ìˆœìœ„ (ì§‘ë‹¨)
                disp_df.to_excel(writer, index=False, sheet_name='ì¢…í•©_ìˆœìœ„_ë¶„ì„')
                
                # ì‹œíŠ¸ 2: ê°œì¸ë³„ ìƒì„¸ ê°€ì¤‘ì¹˜ (ëˆ„ê°€, ì–¸ì œ, ë¬´ì—‡ì„ ë†’ê²Œ ì¤¬ë‚˜)
                personal_df.to_excel(writer, index=False, sheet_name='ê°œì¸ë³„_ìƒì„¸_ê²°ê³¼')
                
                # ì‹œíŠ¸ 3: ì‘ë‹µ í˜„í™© (CR ì²´í¬)
                status_df.to_excel(writer, index=False, sheet_name='ì‘ë‹µì_í˜„í™©_ë°_CR')
                
                # ì‹œíŠ¸ 4: ì›ë³¸ (ë°±ì—…ìš©)
                df.to_excel(writer, index=False, sheet_name='ì›ë³¸_RAW_ë°ì´í„°')
            
            st.download_button(
                label="ğŸ“Š ì—‘ì…€ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (.xlsx)",
                data=output.getvalue(),
                file_name=f"AHP_Report_{display_name}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary"
            )
            
        else:
            st.error("ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ì´ˆê¸°í™”
    st.divider()
    with st.expander("ğŸ—‘ï¸ ë°ì´í„° ì´ˆê¸°í™”"):
        if st.button("í˜„ì¬ íŒŒì¼ ì‚­ì œ"):
            os.remove(file_path)
            st.rerun()
