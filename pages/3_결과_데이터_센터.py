import streamlit as st
import pandas as pd
import json
import os
import re
import numpy as np
import io

# --------------------------------------------------------------------------
# 1. í˜ì´ì§€ ì„¤ì •
# --------------------------------------------------------------------------
st.set_page_config(page_title="ê²°ê³¼ ë°ì´í„° ì„¼í„°", page_icon="ğŸ“Š", layout="wide")

st.title("ğŸ” ê²°ê³¼ ë°ì´í„° ì„¼í„° (Private)")

DATA_FOLDER = "survey_data"
if not os.path.exists(DATA_FOLDER):
    os.makedirs(DATA_FOLDER)

# --------------------------------------------------------------------------
# 2. AHP ê³„ì‚° ì—”ì§„ (ìˆ˜í•™ ë¡œì§)
# --------------------------------------------------------------------------
# Saatyì˜ ë¬´ì‘ìœ„ ì§€ìˆ˜ (RI)
RI_TABLE = {1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45, 10: 1.49}

def saaty_scale(val):
    """ìŠ¬ë¼ì´ë” ê°’(-8~8)ì„ Saaty ì²™ë„(1/9~9)ë¡œ ë³€í™˜"""
    val = int(val)
    if val == 0: return 1
    elif val < 0: return 1 / (abs(val) + 1)
    else: return val + 1

def calculate_ahp(items, pairs_data):
    """ê°€ì¤‘ì¹˜ì™€ CR(ì¼ê´€ì„± ë¹„ìœ¨)ì„ ë™ì‹œì— ê³„ì‚°"""
    n = len(items)
    if n == 0: return {}, 0
    
    # 1. ìŒëŒ€ë¹„êµ í–‰ë ¬ ìƒì„±
    matrix = np.ones((n, n))
    item_map = {name: i for i, name in enumerate(items)}

    for key, val in pairs_data.items():
        # ë°ì´í„° íŒŒì‹± ("A vs B")
        if " vs " in key:
            parts = key.split(" vs ")
            item_a, item_b = parts[0].strip(), parts[1].strip()
            
            if item_a in item_map and item_b in item_map:
                idx_a, idx_b = item_map[item_a], item_map[item_b]
                scale_val = saaty_scale(val)
                matrix[idx_a][idx_b] = scale_val
                matrix[idx_b][idx_a] = 1 / scale_val

    # 2. ê°€ì¤‘ì¹˜ ê³„ì‚° (ê¸°í•˜í‰ê· ë²•)
    geo_means = []
    for i in range(n):
        row_prod = np.prod(matrix[i])
        geo_means.append(row_prod ** (1/n))
    
    total_sum = sum(geo_means)
    weights = [gm / total_sum for gm in geo_means]
    weights_dict = {items[i]: w for i, w in enumerate(weights)}

    # 3. CR(ì¼ê´€ì„± ë¹„ìœ¨) ê³„ì‚°
    if n <= 2:
        cr = 0.0
    else:
        lambda_max = 0
        for i in range(n):
            col_sum = np.sum(matrix[:, i])
            lambda_max += col_sum * weights[i]
            
        ci = (lambda_max - n) / (n - 1)
        ri = RI_TABLE.get(n, 1.49)
        cr = ci / ri if ri != 0 else 0

    return weights_dict, cr

def process_single_response(raw_json):
    """í•œ ëª…ì˜ ì‘ë‹µ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¤‘ì¹˜ì™€ CR ë°˜í™˜"""
    try:
        data = json.loads(raw_json)
    except:
        return None, 9.9 # íŒŒì‹± ì—ëŸ¬

    groups, items_in_group = {}, {}

    # ë°ì´í„° ë¶„ë¥˜
    for full_key, val in data.items():
        match = re.match(r"\[(.*?)\](.*)", full_key)
        if match:
            group_name, pair_key = match.group(1), match.group(2).strip()
            if group_name not in groups: 
                groups[group_name] = {}
                items_in_group[group_name] = set()
            
            groups[group_name][pair_key] = val
            
            if " vs " in pair_key:
                a, b = pair_key.split(" vs ")
                items_in_group[group_name].add(a.strip())
                items_in_group[group_name].add(b.strip())

    calculated_weights = {}
    max_cr = 0.0 
    
    # 1ì°¨ ê¸°ì¤€ ê³„ì‚° (ë³´í†µ '1.' ì´ë‚˜ 'ê¸°ì¤€'ì´ ë“¤ì–´ê°)
    main_group_name = next((k for k in groups.keys() if "1." in k or "ê¸°ì¤€" in k), None)
    
    if main_group_name:
        items = list(items_in_group[main_group_name])
        w, cr = calculate_ahp(items, groups[main_group_name])
        calculated_weights["MAIN"] = w
        if cr > max_cr: max_cr = cr
    else:
        return None, 9.9 

    # 2ì°¨ ì„¸ë¶€í•­ëª© ê³„ì‚° ë° ì¢…í•©
    final_rows = []
    
    for group_name, pairs in groups.items():
        if group_name == main_group_name: continue
        
        # ë¶€ëª¨ ì°¾ê¸°
        parent_name = None
        for m_item in calculated_weights["MAIN"].keys():
            if m_item in group_name:
                parent_name = m_item
                break
        
        if parent_name:
            items = list(items_in_group[group_name])
            sub_w, sub_cr = calculate_ahp(items, pairs)
            
            if sub_cr > max_cr: max_cr = sub_cr
            
            p_weight = calculated_weights["MAIN"][parent_name]
            for s_item, s_weight in sub_w.items():
                final_rows.append({
                    "1ì°¨ ê¸°ì¤€": parent_name,
                    "1ì°¨ ê°€ì¤‘ì¹˜": p_weight,
                    "2ì°¨ í•­ëª©": s_item,
                    "2ì°¨ ê°€ì¤‘ì¹˜": s_weight,
                    "ì¢…í•© ê°€ì¤‘ì¹˜": p_weight * s_weight
                })

    return final_rows, max_cr

# --------------------------------------------------------------------------
# 3. ë©”ì¸ UI (ë¶„ì„ ë° ì‹œê°í™”)
# --------------------------------------------------------------------------
# ì‚¬ì´ë“œë°”: ë¹„ë°€ë²ˆí˜¸ ì¸ì¦
with st.sidebar:
    st.header("ğŸ”‘ ì ‘ì† ì¸ì¦")
    user_key = st.text_input("í”„ë¡œì íŠ¸ ë¹„ë°€ë²ˆí˜¸(Key)", type="password")

if not user_key:
    st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— **í”„ë¡œì íŠ¸ ë¹„ë°€ë²ˆí˜¸**ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

# íŒŒì¼ í•„í„°ë§
all_files = [f for f in os.listdir(DATA_FOLDER) if f.endswith(".csv")]
my_files = [f for f in all_files if f.startswith(f"{user_key}_")]

if not my_files:
    st.error(f"ë¹„ë°€ë²ˆí˜¸ '{user_key}'ì— í•´ë‹¹í•˜ëŠ” í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

st.success(f"ì¸ì¦ ì„±ê³µ! '{user_key}' í”„ë¡œì íŠ¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
selected_file = st.selectbox("ğŸ“‚ ë¶„ì„í•  ë°ì´í„° íŒŒì¼ ì„ íƒ:", my_files)

if selected_file:
    file_path = os.path.join(DATA_FOLDER, selected_file)
    df = pd.read_csv(file_path)
    
    st.divider()
    display_name = selected_file.replace(f"{user_key}_", "").replace(".csv", "").replace("_", " ")
    st.subheader(f"ğŸ“ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ: {display_name}")
    st.caption(f"ì´ ì‘ë‹µ ë°ì´í„°: {len(df)}ê±´")
    
    # [í•µì‹¬] ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
    if st.button("ğŸ§® AHP ë¶„ì„ ì‹¤í–‰ (ìˆœìœ„/ì¼ê´€ì„±/ì—‘ì…€)", type="primary"):
        
        valid_data = [] # ìœ íš¨í•œ ë°ì´í„° ëª¨ìŒ
        status_list = [] # O/X í˜„í™©íŒ
        
        # 1. ë°ì´í„° í•œ ì¤„ì”© êº¼ë‚´ì„œ ë¶„ì„
        for idx, row in df.iterrows():
            try:
                res_rows, person_cr = process_single_response(row['Raw_Data'])
                
                if res_rows is None: 
                    continue # ë°ì´í„° ê¹¨ì§ ë°©ì§€

                # ìœ íš¨ì„± íŒì • (CR <= 0.1)
                is_valid = person_cr <= 0.1
                valid_mark = "O" if is_valid else "X"
                
                status = {
                    "ì‘ë‹µì": row.get('Respondent', f'ì°¸ì—¬ì {idx+1}'),
                    "ì‘ì„±ì‹œê°„": row['Time'],
                    "ìµœëŒ€ CR": round(person_cr, 4),
                    "íŒì •": valid_mark
                }
                status_list.append(status)
                
                if is_valid:
                    valid_data.extend(res_rows)
                    
            except Exception as e:
                continue 

        # -------------------------------------------------------
        # [ê¸°ëŠ¥ 1] ì¼ê´€ì„± ê²€ì¦ í‘œ (CR Check)
        # -------------------------------------------------------
        st.markdown("### 1ï¸âƒ£ ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ (CR Check)")
        st.caption("CR(ì¼ê´€ì„± ë¹„ìœ¨)ì´ 0.1 ì´í•˜ì¸ ë°ì´í„°ë§Œ **'O'**ë¡œ íŒì •í•˜ì—¬ ë¶„ì„ì— í¬í•¨í•©ë‹ˆë‹¤.")
        
        status_df = pd.DataFrame(status_list)
        if not status_df.empty:
            # ìƒ‰ìƒ ì ìš© í•¨ìˆ˜
            def color_validity(val):
                color = '#e6fcf5' if val == 'O' else '#fff5f5'
                return f'background-color: {color}'
            
            st.dataframe(status_df.style.applymap(color_validity, subset=['íŒì •']), use_container_width=True)
            
            valid_count = len(status_df[status_df['íŒì •'] == 'O'])
            st.info(f"ì „ì²´ {len(status_df)}ëª… ì¤‘ **{valid_count}ëª…(O)**ì˜ ìœ íš¨ ë°ì´í„°ë¥¼ í™œìš©í•©ë‹ˆë‹¤.")
        else:
            st.warning("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # -------------------------------------------------------
        # [ê¸°ëŠ¥ 2] ìµœì¢… ìˆœìœ„ ì‚°ì¶œ (Ranking)
        # -------------------------------------------------------
        if valid_data:
            res_df = pd.DataFrame(valid_data)
            
            # í‰ê·  ê³„ì‚°
            final_df = res_df.groupby(['1ì°¨ ê¸°ì¤€', '2ì°¨ í•­ëª©']).mean(numeric_only=True).reset_index()
            final_df = final_df.sort_values(by='ì¢…í•© ê°€ì¤‘ì¹˜', ascending=False)
            final_df['ìˆœìœ„'] = range(1, len(final_df) + 1)
            
            # ë³´ì—¬ì¤„ ì»¬ëŸ¼ ì •ë¦¬
            disp_df = final_df[['ìˆœìœ„', '1ì°¨ ê¸°ì¤€', '2ì°¨ í•­ëª©', 'ì¢…í•© ê°€ì¤‘ì¹˜', '1ì°¨ ê°€ì¤‘ì¹˜', '2ì°¨ ê°€ì¤‘ì¹˜']]
            
            st.divider()
            st.markdown("### ğŸ† 2ï¸âƒ£ ìµœì¢… ì¢…í•© ìˆœìœ„ (Global Rank)")
            
            # ìˆœìœ„í‘œ ì¶œë ¥ (ìƒ‰ì¹  ê¸°ëŠ¥ í¬í•¨, ì—ëŸ¬ ì‹œ ê¸°ë³¸í‘œ ì¶œë ¥)
            try:
                st.dataframe(
                    disp_df.style.format({
                        'ì¢…í•© ê°€ì¤‘ì¹˜': '{:.4f}', '1ì°¨ ê°€ì¤‘ì¹˜': '{:.4f}', '2ì°¨ ê°€ì¤‘ì¹˜': '{:.4f}'
                    }).background_gradient(subset=['ì¢…í•© ê°€ì¤‘ì¹˜'], cmap='Blues'),
                    use_container_width=True
                )
            except:
                st.dataframe(disp_df, use_container_width=True)

            # -------------------------------------------------------
            # [ê¸°ëŠ¥ 3] ì—‘ì…€ ë‹¤ìš´ë¡œë“œ (Excel Export)
            # -------------------------------------------------------
            st.divider()
            st.markdown("### ğŸ“¥ ê²°ê³¼ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ")
            
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                disp_df.to_excel(writer, index=False, sheet_name='ì¢…í•©ìˆœìœ„_ê²°ê³¼')
                status_df.to_excel(writer, index=False, sheet_name='ìœ íš¨ì„±_ê²€ì‚¬')
                df.to_excel(writer, index=False, sheet_name='ì›ë³¸_ë°ì´í„°')
            
            st.download_button(
                label="ğŸ“„ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (.xlsx)",
                data=output.getvalue(),
                file_name=f"AHP_Analysis_{display_name}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary"
            )
            
        else:
            st.error("ğŸš¨ ë¶„ì„ì— í™œìš©í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ ë°ì´í„°(O)ê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")

    # [ê´€ë¦¬ì ê¸°ëŠ¥] ë°ì´í„° ì´ˆê¸°í™”
    st.divider()
    with st.expander("ğŸ—‘ï¸ ë°ì´í„° ì´ˆê¸°í™” (ê´€ë¦¬ììš©)"):
        st.warning("âš ï¸ ì£¼ì˜: ì´ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ í˜„ì¬ ì„ íƒëœ íŒŒì¼ì´ ì˜êµ¬ ì‚­ì œë©ë‹ˆë‹¤.")
        if st.button("í˜„ì¬ íŒŒì¼ ì‚­ì œí•˜ê¸°"):
            try:
                os.remove(file_path)
                st.success("íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤.")
                st.rerun()
            except:
                st.error("ì‚­ì œ ì‹¤íŒ¨")
