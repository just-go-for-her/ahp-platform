import streamlit as st
import pandas as pd
import json
import os
import re
import numpy as np
import io

# --------------------------------------------------------------------------
# 1. í˜ì´ì§€ ì„¤ì •
# --------------------------------------------------------------------------
st.set_page_config(page_title="ê²°ê³¼ ë°ì´í„° ì„¼í„°", page_icon="ğŸ“Š", layout="wide")

st.title("ğŸ” ê²°ê³¼ ë°ì´í„° ì„¼í„° (Private)")

DATA_FOLDER = "survey_data"
if not os.path.exists(DATA_FOLDER):
    os.makedirs(DATA_FOLDER)

# --------------------------------------------------------------------------
# 2. AHP ê³„ì‚° ì—”ì§„
# --------------------------------------------------------------------------
RI_TABLE = {1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45, 10: 1.49}

def saaty_scale(val):
    val = int(val)
    if val == 0: return 1
    elif val < 0: return 1 / (abs(val) + 1)
    else: return val + 1

def calculate_ahp(items, pairs_data):
    n = len(items)
    if n == 0: return {}, 0
    
    matrix = np.ones((n, n))
    item_map = {name: i for i, name in enumerate(items)}

    for key, val in pairs_data.items():
        if " vs " in key:
            parts = key.split(" vs ")
            item_a, item_b = parts[0].strip(), parts[1].strip()
            if item_a in item_map and item_b in item_map:
                idx_a, idx_b = item_map[item_a], item_map[item_b]
                scale_val = saaty_scale(val)
                matrix[idx_a][idx_b] = scale_val
                matrix[idx_b][idx_a] = 1 / scale_val

    geo_means = []
    for i in range(n):
        row_prod = np.prod(matrix[i])
        geo_means.append(row_prod ** (1/n))
    
    total_sum = sum(geo_means)
    weights = [gm / total_sum for gm in geo_means]
    weights_dict = {items[i]: w for i, w in enumerate(weights)}

    if n <= 2: cr = 0.0
    else:
        lambda_max = 0
        for i in range(n):
            col_sum = np.sum(matrix[:, i])
            lambda_max += col_sum * weights[i]
        ci = (lambda_max - n) / (n - 1)
        ri = RI_TABLE.get(n, 1.49)
        cr = ci / ri if ri != 0 else 0

    return weights_dict, cr

def process_single_response(raw_json):
    try:
        data = json.loads(raw_json)
    except:
        return None, 9.9 

    groups, items_in_group = {}, {}
    for full_key, val in data.items():
        match = re.match(r"\[(.*?)\](.*)", full_key)
        if match:
            group_name, pair_key = match.group(1), match.group(2).strip()
            if group_name not in groups: 
                groups[group_name] = {}
                items_in_group[group_name] = set()
            groups[group_name][pair_key] = val
            if " vs " in pair_key:
                a, b = pair_key.split(" vs ")
                items_in_group[group_name].add(a.strip())
                items_in_group[group_name].add(b.strip())

    calculated_weights = {}
    max_cr = 0.0 
    
    main_group_name = next((k for k in groups.keys() if "1." in k or "ê¸°ì¤€" in k), None)
    
    if main_group_name:
        items = list(items_in_group[main_group_name])
        w, cr = calculate_ahp(items, groups[main_group_name])
        calculated_weights["MAIN"] = w
        if cr > max_cr: max_cr = cr
    else:
        return None, 9.9 

    final_rows = []
    
    for group_name, pairs in groups.items():
        if group_name == main_group_name: continue
        
        parent_name = None
        for m_item in calculated_weights["MAIN"].keys():
            if m_item in group_name:
                parent_name = m_item
                break
        
        if parent_name:
            items = list(items_in_group[group_name])
            sub_w, sub_cr = calculate_ahp(items, pairs)
            if sub_cr > max_cr: max_cr = sub_cr
            
            p_weight = calculated_weights["MAIN"][parent_name]
            for s_item, s_weight in sub_w.items():
                final_weight = p_weight * s_weight
                final_rows.append({
                    "1ì°¨ ê¸°ì¤€": parent_name,
                    "1ì°¨ ê°€ì¤‘ì¹˜": p_weight,
                    "2ì°¨ í•­ëª©": s_item,
                    "2ì°¨ ê°€ì¤‘ì¹˜": s_weight,
                    "ì¢…í•© ê°€ì¤‘ì¹˜": final_weight
                })

    return final_rows, max_cr

# --------------------------------------------------------------------------
# 3. ë©”ì¸ UI
# --------------------------------------------------------------------------
with st.sidebar:
    st.header("ğŸ”‘ ì ‘ì† ì¸ì¦")
    user_key = st.text_input("í”„ë¡œì íŠ¸ ë¹„ë°€ë²ˆí˜¸(Key)", type="password")

if not user_key:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì— **í”„ë¡œì íŠ¸ ë¹„ë°€ë²ˆí˜¸**ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

all_files = [f for f in os.listdir(DATA_FOLDER) if f.endswith(".csv")]
my_files = [f for f in all_files if f.startswith(f"{user_key}_")]

if not my_files:
    st.error(f"ë¹„ë°€ë²ˆí˜¸ '{user_key}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

st.success(f"ì¸ì¦ ì„±ê³µ! í”„ë¡œì íŠ¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
selected_file = st.selectbox("ğŸ“‚ ë¶„ì„í•  ë°ì´í„° ì„ íƒ:", my_files)

if selected_file:
    file_path = os.path.join(DATA_FOLDER, selected_file)
    df = pd.read_csv(file_path)
    
    st.divider()
    display_name = selected_file.replace(f"{user_key}_", "").replace(".csv", "").replace("_", " ")
    st.subheader(f"ğŸ“ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ: {display_name}")
    st.caption(f"ì´ ì‘ë‹µ ìˆ˜: {len(df)}ëª…")
    
    if st.button("ğŸ§® ë¶„ì„ ì‹¤í–‰ (ë¦¬í¬íŠ¸ ìƒì„±)", type="primary"):
        
        valid_data_rows = []        # ì§‘ë‹¨ ë¶„ì„ìš© (ìœ íš¨ ë°ì´í„°ë§Œ ì·¨í•©)
        individual_detail_rows = [] # ìœ íš¨í•œ ê°œì¸ë³„ ìƒì„¸ (ìˆœìœ„ í¬í•¨)
        invalid_detail_rows = []    # [ì¶”ê°€ë¨] ë¶€ì í•© ê°œì¸ë³„ ìƒì„¸ (ìˆœìœ„ í¬í•¨)
        status_list = []            # í˜„í™©íŒ
        
        for idx, row in df.iterrows():
            try:
                res_rows, person_cr = process_single_response(row['Raw_Data'])
                if res_rows is None: continue

                is_valid = person_cr <= 0.1
                
                # 1. í˜„í™©íŒìš© ë°ì´í„° (í™”ë©´ í‘œì‹œìš©)
                status = {
                    "ìˆœë²ˆ": idx + 1,
                    "ì‘ë‹µì": row.get('Respondent', 'ìµëª…'),
                    "ì‘ì„±ì‹œê°„": row['Time'],
                    "ì¼ê´€ì„±ì§€ìˆ˜(CR)": round(person_cr, 4),
                    "ìœ íš¨íŒì •": "O" if is_valid else "X"
                }
                status_list.append(status)
                
                # 2. ê°œì¸ë³„ ìƒì„¸ ë°ì´í„° ê°€ê³µ (ê³µí†µ)
                person_df = pd.DataFrame(res_rows)
                person_df = person_df.sort_values(by='ì¢…í•© ê°€ì¤‘ì¹˜', ascending=False)
                person_df['ìˆœìœ„'] = range(1, len(person_df) + 1)
                
                # ì¸ì ì‚¬í•­ ë° CR ì •ë³´ ì¶”ê°€
                person_df.insert(0, 'ì‘ë‹µì', row.get('Respondent', 'ìµëª…'))
                person_df.insert(1, 'ì‘ì„±ì‹œê°„', row['Time'])
                person_df.insert(2, 'CR', round(person_cr, 4))
                
                # 3. ìœ íš¨ì„± ì—¬ë¶€ì— ë”°ë¥¸ ë¶„ë¦¬ ì €ì¥
                if is_valid:
                    # ìœ íš¨í•¨ -> ì¢…í•© ë¶„ì„ ë° ìœ íš¨ ìƒì„¸ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    valid_data_rows.extend(res_rows)
                    individual_detail_rows.extend(person_df.to_dict('records'))
                else:
                    # ë¶€ì í•© -> ë¶€ì í•© ìƒì„¸ ë¦¬ìŠ¤íŠ¸ì—ë§Œ ì¶”ê°€ (ì¢…í•© ë¶„ì„ ì œì™¸)
                    invalid_detail_rows.extend(person_df.to_dict('records'))
                    
            except Exception as e:
                continue 

        # -------------------------------------------------------
        # í™”ë©´ ì¶œë ¥
        # -------------------------------------------------------
        
        # 1. ìœ íš¨ì„± ê²€ì‚¬ í˜„í™©íŒ
        st.markdown("### 1ï¸âƒ£ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ í˜„í™©")
        status_df = pd.DataFrame(status_list)
        
        if not status_df.empty:
            def color_val(val):
                return 'background-color: #e6fcf5' if val == 'O' else 'background-color: #fff5f5; color: red;'
            st.dataframe(status_df.style.applymap(color_val, subset=['ìœ íš¨íŒì •']), use_container_width=True)
            
            valid_count = len(status_df[status_df['ìœ íš¨íŒì •'] == 'O'])
            st.info(f"ì´ {len(status_df)}ëª… ì¤‘ **{valid_count}ëª…(O)**ì˜ ë°ì´í„°ë§Œ ì¢…í•© ë¶„ì„ì— ë°˜ì˜ë©ë‹ˆë‹¤.")
        
        # 2. ì¢…í•© ìˆœìœ„ (ì§‘ë‹¨ í‰ê· ) - ìœ íš¨í•œ ë°ì´í„°ë§Œ ì‚¬ìš©
        if valid_data_rows:
            res_df = pd.DataFrame(valid_data_rows)
            final_df = res_df.groupby(['1ì°¨ ê¸°ì¤€', '2ì°¨ í•­ëª©']).mean(numeric_only=True).reset_index()
            final_df = final_df.sort_values(by='ì¢…í•© ê°€ì¤‘ì¹˜', ascending=False)
            final_df['ìˆœìœ„'] = range(1, len(final_df) + 1)
            
            disp_df = final_df[['ìˆœìœ„', '1ì°¨ ê¸°ì¤€', '2ì°¨ í•­ëª©', 'ì¢…í•© ê°€ì¤‘ì¹˜']]
            
            st.divider()
            st.markdown("### ğŸ† 2ï¸âƒ£ ìµœì¢… ì¢…í•© ìˆœìœ„ (ìœ íš¨ ë°ì´í„° ê¸°ì¤€)")
            st.dataframe(disp_df.style.background_gradient(subset=['ì¢…í•© ê°€ì¤‘ì¹˜'], cmap='Blues'), use_container_width=True)

            # -------------------------------------------------------
            # [ì—‘ì…€ ë‹¤ìš´ë¡œë“œ]
            # -------------------------------------------------------
            st.divider()
            st.markdown("### ğŸ“¥ ìƒì„¸ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ")
            
            # DataFrame ë³€í™˜
            personal_valid_df = pd.DataFrame(individual_detail_rows) # ìœ íš¨
            personal_invalid_df = pd.DataFrame(invalid_detail_rows)  # ë¶€ì í•© [ì¶”ê°€ë¨]
            
            # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬ (ë³´ê¸° ì¢‹ê²Œ)
            cols = ['ì‘ë‹µì', 'ì‘ì„±ì‹œê°„', 'CR', 'ìˆœìœ„', '1ì°¨ ê¸°ì¤€', '1ì°¨ ê°€ì¤‘ì¹˜', '2ì°¨ í•­ëª©', '2ì°¨ ê°€ì¤‘ì¹˜', 'ì¢…í•© ê°€ì¤‘ì¹˜']
            
            if not personal_valid_df.empty:
                personal_valid_df = personal_valid_df[[c for c in cols if c in personal_valid_df.columns]]
            
            if not personal_invalid_df.empty:
                personal_invalid_df = personal_invalid_df[[c for c in cols if c in personal_invalid_df.columns]]

            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # ì‹œíŠ¸ 1: ì¢…í•© ìˆœìœ„ (ìœ íš¨ê°’ ê¸°ì¤€)
                disp_df.to_excel(writer, index=False, sheet_name='ì¢…í•©_ìˆœìœ„_ë¶„ì„')
                
                # ì‹œíŠ¸ 2: ìœ íš¨í•œ ê°œì¸ë³„ ìƒì„¸
                personal_valid_df.to_excel(writer, index=False, sheet_name='ê°œì¸ë³„_ìƒì„¸(ìœ íš¨)')
                
                # ì‹œíŠ¸ 3: [NEW] ë¶€ì í•©í•œ ê°œì¸ë³„ ìƒì„¸ (ë³„ë„ ì‹œíŠ¸)
                if not personal_invalid_df.empty:
                    personal_invalid_df.to_excel(writer, index=False, sheet_name='ë¶€ì í•©_ìƒì„¸_ê²°ê³¼')
                
                # ì‹œíŠ¸ 4: ì „ì²´ ì‘ë‹µì í˜„í™© (O/X í™•ì¸ìš©)
                status_df.to_excel(writer, index=False, sheet_name='ì‘ë‹µì_í˜„í™©_ë°_CR')
                
                # ì‹œíŠ¸ 5: ì›ë³¸ RAW ë°ì´í„°
                df.to_excel(writer, index=False, sheet_name='ì›ë³¸_RAW_ë°ì´í„°')
            
            st.download_button(
                label="ğŸ“Š ì—‘ì…€ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (.xlsx)",
                data=output.getvalue(),
                file_name=f"AHP_Report_{display_name}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary"
            )
            
            if not personal_invalid_df.empty:
                with st.expander("âš ï¸ ë¶€ì í•© ë°ì´í„°(CR > 0.1) ë¯¸ë¦¬ë³´ê¸°"):
                    st.warning("ì•„ë˜ ë°ì´í„°ëŠ” ì¼ê´€ì„±ì´ ë¶€ì¡±í•˜ì—¬ ì¢…í•© ë¶„ì„ì—ì„œ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì—‘ì…€ì˜ 'ë¶€ì í•©_ìƒì„¸_ê²°ê³¼' ì‹œíŠ¸ì—ì„œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                    st.dataframe(personal_invalid_df)
            
        else:
            st.error("ìœ íš¨í•œ ë°ì´í„°(CR <= 0.1)ê°€ í•˜ë‚˜ë„ ì—†ì–´ ì¢…í•© ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ë”ë¼ë„ ë¶€ì í•© ë°ì´í„°ë§Œì´ë¼ë„ ì—‘ì…€ë¡œ ë°›ê³  ì‹¶ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì œê³µ
            if invalid_detail_rows:
                st.warning("í•˜ì§€ë§Œ ë¶€ì í•© ë°ì´í„°ì— ëŒ€í•œ ìƒì„¸ ë‚´ì—­ì€ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                personal_invalid_df = pd.DataFrame(invalid_detail_rows)
                
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    personal_invalid_df.to_excel(writer, index=False, sheet_name='ë¶€ì í•©_ìƒì„¸_ê²°ê³¼')
                    status_df.to_excel(writer, index=False, sheet_name='ì‘ë‹µì_í˜„í™©_ë°_CR')
                    df.to_excel(writer, index=False, sheet_name='ì›ë³¸_RAW_ë°ì´í„°')
                
                st.download_button(
                    label="ğŸ“Š ë¶€ì í•© ë°ì´í„°ë§Œ ë‹¤ìš´ë¡œë“œ (.xlsx)",
                    data=output.getvalue(),
                    file_name=f"AHP_Invalid_Only_{display_name}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

    # ì´ˆê¸°í™”
    st.divider()
    with st.expander("ğŸ—‘ï¸ ë°ì´í„° ì´ˆê¸°í™”"):
        if st.button("í˜„ì¬ íŒŒì¼ ì‚­ì œ"):
            os.remove(file_path)
            st.rerun()
