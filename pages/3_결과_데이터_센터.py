import streamlit as st
import pandas as pd
import numpy as np
import json
import io
import os

# ==============================================================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==============================================================================
st.set_page_config(page_title="ê²°ê³¼ ë°ì´í„° ì„¼í„°", page_icon="ğŸ“Š", layout="wide")
st.title("ğŸ“Š AHP ê²°ê³¼ ë°ì´í„° ì„¼í„°")

# ë°ì´í„° ì €ì¥ì†Œ ê²½ë¡œ
DATA_FOLDER = "survey_data"
if not os.path.exists(DATA_FOLDER):
    os.makedirs(DATA_FOLDER)

# ==============================================================================
# [í•¨ìˆ˜] AHP í•µì‹¬ ì—”ì§„ (ìˆ˜ì • ê°€ì¤‘ì¹˜ & CR ê³„ì‚°)
# ==============================================================================
def calculate_ahp_metrics(comparisons):
    """
    ì…ë ¥: {"A vs B": 3, ...} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    ì¶œë ¥: (í•­ëª© ë¦¬ìŠ¤íŠ¸, ê°€ì¤‘ì¹˜ ë°°ì—´, CR ê°’)
    """
    # 1. í•­ëª© ì¶”ì¶œ ë° ë§¤í•‘
    items = set()
    for pair in comparisons.keys():
        if " vs " in pair:
            a, b = pair.split(" vs ")
            items.add(a); items.add(b)
    items = sorted(list(items))
    n = len(items)
    item_map = {name: i for i, name in enumerate(items)}

    # 2. í–‰ë ¬ ìƒì„±
    matrix = np.ones((n, n))
    for pair, val in comparisons.items():
        try:
            if " vs " in pair:
                a, b = pair.split(" vs ")
                val = float(val)
                if a in item_map and b in item_map:
                    i, j = item_map[a], item_map[b]
                    matrix[i][j] = val
                    matrix[j][i] = 1 / val
        except: continue

    # 3. ìˆ˜ì • ê°€ì¤‘ì¹˜ ê³„ì‚° (ê³ ìœ ë²¡í„°ë²• - Eigenvector Method)
    try:
        eigvals, eigvecs = np.linalg.eig(matrix)
        max_idx = np.argmax(eigvals)
        max_eigval = eigvals[max_idx].real
        weights = eigvecs[:, max_idx].real
        weights = weights / weights.sum() # ì •ê·œí™”
    except:
        # ì˜ˆì™¸ ì²˜ë¦¬: ê¸°í•˜í‰ê· ë²•
        weights = np.ones(n)
        for i in range(n):
            weights[i] = np.prod(matrix[i]) ** (1/n)
        weights = weights / weights.sum()
        max_eigval = n

    # 4. CR(ì¼ê´€ì„± ë¹„ìœ¨) ê³„ì‚°
    ri_table = {1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45}
    ci = (max_eigval - n) / (n - 1) if n > 1 else 0
    ri = ri_table.get(n, 1.49)
    cr = ci / ri if ri != 0 else 0

    return items, weights, cr

# ==============================================================================
# [UI] ì‚¬ì´ë“œë°” ì¸ì¦ ë° íŒŒì¼ ì„ íƒ (ìë™ ì—°ë™)
# ==============================================================================
with st.sidebar:
    st.header("ğŸ”‘ ì ‘ì† ì¸ì¦")
    user_key = st.text_input("í”„ë¡œì íŠ¸ ë¹„ë°€ë²ˆí˜¸(Key)", type="password")

if not user_key:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì— **í”„ë¡œì íŠ¸ ë¹„ë°€ë²ˆí˜¸**ë¥¼ ì…ë ¥í•˜ë©´ ë°ì´í„°ê°€ ìë™ ë¡œë“œë©ë‹ˆë‹¤.")
    st.stop()

# íŒŒì¼ ìë™ íƒìƒ‰
all_files = [f for f in os.listdir(DATA_FOLDER) if f.endswith(".csv")]
my_files = [f for f in all_files if f.startswith(f"{user_key}_")]

if not my_files:
    st.error(f"ë¹„ë°€ë²ˆí˜¸ '{user_key}'ë¡œ ì‹œì‘í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

st.sidebar.success(f"ì¸ì¦ ì„±ê³µ! {len(my_files)}ê°œì˜ ë°ì´í„° ë°œê²¬")
selected_file = st.selectbox("ğŸ“‚ ë¶„ì„í•  í”„ë¡œì íŠ¸ ì„ íƒ", my_files)

# ==============================================================================
# [ë©”ì¸] ë°ì´í„° ì²˜ë¦¬ ë° ë¦¬í¬íŠ¸ ìƒì„±
# ==============================================================================
if selected_file:
    file_path = os.path.join(DATA_FOLDER, selected_file)
    raw_df = pd.read_csv(file_path)
    
    st.markdown(f"### ğŸ“„ í”„ë¡œì íŠ¸: **{selected_file.replace(user_key+'_', '').replace('.csv', '')}**")
    
    # ë¶„ì„ìš© ì»¨í…Œì´ë„ˆ
    processed_data = [] # ëª¨ë“  ì‘ë‹µìì˜ ìƒì„¸ ë¶„ì„ ì •ë³´
    valid_weights = []  # ìœ íš¨í•œ ì‘ë‹µìë“¤ì˜ ê°€ì¤‘ì¹˜ ëª¨ìŒ
    
    progress_bar = st.progress(0)
    
    for idx, row in raw_df.iterrows():
        try:
            # JSON íŒŒì‹±
            survey_dict = json.loads(row['Raw_Data'])
            respondent = row['Respondent']
            
            # íƒœìŠ¤í¬ë³„ ë¶„ë¥˜
            tasks = {}
            for k, v in survey_dict.items():
                # k: "[TaskName] A vs B"
                if "]" in k:
                    task_name = k.split("]")[0].replace("[", "")
                    pair = k.split("]")[1].strip()
                    if task_name not in tasks: tasks[task_name] = {}
                    tasks[task_name][pair] = v
            
            # ì‘ë‹µìë³„ ë¶„ì„
            is_valid_respondent = True
            resp_weights = {} # ì´ ì‚¬ëŒì˜ ëª¨ë“  í•­ëª© ê°€ì¤‘ì¹˜
            resp_crs = {}     # ì´ ì‚¬ëŒì˜ íƒœìŠ¤í¬ë³„ CR
            
            for t_name, comps in tasks.items():
                items, w, cr = calculate_ahp_metrics(comps)
                
                # CR ì²´í¬ (í•˜ë‚˜ë¼ë„ 0.1 ë„˜ìœ¼ë©´ ì´ ì‚¬ëŒ ë°ì´í„°ëŠ” ë¬´íš¨)
                if cr > 0.1:
                    is_valid_respondent = False
                
                resp_crs[t_name] = cr
                for i, item in enumerate(items):
                    # Key: "TaskName|ItemName"
                    resp_weights[f"{t_name}|{item}"] = w[i]
            
            # ë°ì´í„° ì €ì¥
            processed_data.append({
                "Respondent": respondent,
                "Time": row['Time'],
                "Is_Valid": is_valid_respondent,
                "CR_Details": str(resp_crs),
                **resp_weights # Flatten weights
            })
            
            if is_valid_respondent:
                valid_weights.append(resp_weights)
                
        except Exception as e:
            st.warning(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì¼ë¶€ ì˜¤ë¥˜ (Row {idx}): {e}")
            
        progress_bar.progress((idx + 1) / len(raw_df))
    
    progress_bar.empty()
    
    # --------------------------------------------------------------------------
    # 2. ë°ì´í„° ë¶„ë¥˜ (ìœ íš¨ vs ë¬´íš¨)
    # --------------------------------------------------------------------------
    full_df = pd.DataFrame(processed_data)
    valid_df = pd.DataFrame(valid_weights) 
    invalid_rows = full_df[full_df['Is_Valid'] == False] if not full_df.empty else pd.DataFrame()
    
    st.divider()
    m1, m2, m3 = st.columns(3)
    m1.metric("ì´ ì‘ë‹µì", f"{len(full_df)}ëª…")
    m2.metric("âœ… ìœ íš¨ ë°ì´í„° (ë¶„ì„ í™œìš©)", f"{len(valid_weights)}ëª…")
    m3.metric("âŒ ì œì™¸ëœ ë°ì´í„° (CR > 0.1)", f"{len(invalid_rows)}ëª…", 
              help="ë…¼ë¦¬ì  ì¼ê´€ì„±ì´ ë¶€ì¡±í•˜ì—¬ í‰ê·  ê³„ì‚°ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")

    if len(valid_weights) == 0:
        st.error("ë¶„ì„í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë“  ë°ì´í„°ê°€ CR > 0.1)")
        st.stop()

    # --------------------------------------------------------------------------
    # 3. ìµœì¢… ê°€ì¤‘ì¹˜ ë° ìˆœìœ„ ì‚°ì¶œ (ì‚°ìˆ  í‰ê·  & ê³„ì¸µ êµ¬ì¡°)
    # --------------------------------------------------------------------------
    avg_weights = valid_df.mean()
    
    tasks_unique = set([k.split("|")[0] for k in avg_weights.index])
    sorted_tasks = sorted(list(tasks_unique))
    
    # [1. ëŒ€í•­ëª©] ì²˜ëŸ¼ ìˆ«ìê°€ ìˆëŠ” ê²½ìš° ì •ë ¬ë¨
    main_task = sorted_tasks[0] 
    sub_tasks = sorted_tasks[1:]
    
    final_report = []
    
    main_items = [k for k in avg_weights.index if k.startswith(main_task)]
    
    for m_key in main_items:
        m_name = m_key.split("|")[1]
        m_weight = avg_weights[m_key]
        
        # 1. ëŒ€í•­ëª© í–‰ ì¶”ê°€
        final_report.append({
            "êµ¬ë¶„": "ëŒ€í•­ëª©",
            "ëŒ€í•­ëª©ëª…": m_name,
            "ì†Œí•­ëª©ëª…": "-",
            "ëŒ€í•­ëª© ê°€ì¤‘ì¹˜": m_weight,
            "ì†Œí•­ëª© ê°€ì¤‘ì¹˜": 0, 
            "ìµœì¢… ê°€ì¤‘ì¹˜": m_weight,
            "ìˆœìœ„": 0 
        })
        
        # 2. ì´ ëŒ€í•­ëª©ì— ì†í•˜ëŠ” ì†Œí•­ëª© ì°¾ê¸°
        matching_sub_task = None
        for st_name in sub_tasks:
            if m_name in st_name:
                matching_sub_task = st_name
                break
        
        if matching_sub_task:
            sub_items = [k for k in avg_weights.index if k.startswith(matching_sub_task)]
            
            temp_subs = []
            for s_key in sub_items:
                s_name = s_key.split("|")[1]
                s_weight = avg_weights[s_key] 
                global_w = m_weight * s_weight 
                temp_subs.append({
                    "êµ¬ë¶„": "ì†Œí•­ëª©",
                    "ëŒ€í•­ëª©ëª…": m_name,
                    "ì†Œí•­ëª©ëª…": s_name,
                    "ëŒ€í•­ëª© ê°€ì¤‘ì¹˜": m_weight,
                    "ì†Œí•­ëª© ê°€ì¤‘ì¹˜": s_weight,
                    "ìµœì¢… ê°€ì¤‘ì¹˜": global_w
                })
            
            # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            temp_subs.sort(key=lambda x: x["ìµœì¢… ê°€ì¤‘ì¹˜"], reverse=True)
            final_report.extend(temp_subs)

    report_df = pd.DataFrame(final_report)
    
    # ìˆœìœ„ ë§¤ê¸°ê¸°
    sub_mask = report_df['êµ¬ë¶„'] == 'ì†Œí•­ëª©'
    if sub_mask.any():
        report_df.loc[sub_mask, 'ìˆœìœ„'] = report_df.loc[sub_mask, 'ìµœì¢… ê°€ì¤‘ì¹˜'].rank(ascending=False).astype(int)
    
    main_mask = report_df['êµ¬ë¶„'] == 'ëŒ€í•­ëª©'
    if main_mask.any():
        report_df.loc[main_mask, 'ìˆœìœ„'] = report_df.loc[main_mask, 'ìµœì¢… ê°€ì¤‘ì¹˜'].rank(ascending=False).astype(int)

    # --------------------------------------------------------------------------
    # 4. í™”ë©´ ì¶œë ¥
    # --------------------------------------------------------------------------
    st.subheader("ğŸ† ìµœì¢… ê°€ì¤‘ì¹˜ ë° ìˆœìœ„ ë¦¬í¬íŠ¸")
    st.caption("ìˆ˜ì • ê°€ì¤‘ì¹˜(Corrected Weight) ì ìš© ë° ì‚°ìˆ  í‰ê· (AIP) ì§‘ê³„ ê²°ê³¼")
    
    display_df = report_df.copy()
    
    cols_to_format = ["ëŒ€í•­ëª© ê°€ì¤‘ì¹˜", "ì†Œí•­ëª© ê°€ì¤‘ì¹˜", "ìµœì¢… ê°€ì¤‘ì¹˜"]
    for c in cols_to_format:
        display_df[c] = display_df[c].apply(lambda x: f"{x:.4f}" if x > 0 else "")
        
    display_df['ìˆœìœ„'] = display_df['ìˆœìœ„'].apply(lambda x: f"{int(x)}ìœ„")
    
    display_df.loc[display_df['êµ¬ë¶„'] == 'ëŒ€í•­ëª©', 'ì†Œí•­ëª© ê°€ì¤‘ì¹˜'] = ""
    display_df.loc[display_df['êµ¬ë¶„'] == 'ëŒ€í•­ëª©', 'ì†Œí•­ëª©ëª…'] = ""
    
    final_cols = ["êµ¬ë¶„", "ëŒ€í•­ëª©ëª…", "ì†Œí•­ëª©ëª…", "ëŒ€í•­ëª© ê°€ì¤‘ì¹˜", "ì†Œí•­ëª© ê°€ì¤‘ì¹˜", "ìµœì¢… ê°€ì¤‘ì¹˜", "ìˆœìœ„"]
    st.dataframe(display_df[final_cols], use_container_width=True, hide_index=True)
    
    # --------------------------------------------------------------------------
    # 5. Excel ë‹¤ìš´ë¡œë“œ (ì—”ì§„ ë³€ê²½: openpyxl)
    # --------------------------------------------------------------------------
    output = io.BytesIO()
    # [ìˆ˜ì •ë¨] xlsxwriter ëŒ€ì‹  openpyxl ì‚¬ìš© (requirements.txt í˜¸í™˜)
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        display_df[final_cols].to_excel(writer, sheet_name='1_ìµœì¢…_ë¶„ì„_ê²°ê³¼', index=False)
        raw_df.to_excel(writer, sheet_name='2_ì „ì²´_ì›ë³¸_ë°ì´í„°', index=False)
        if not invalid_rows.empty:
            invalid_export = invalid_rows[["Respondent", "Time", "CR_Details"]]
            invalid_export.to_excel(writer, sheet_name='3_ì œì™¸ëœ_ë°ì´í„°_ì˜¤ë¥˜ëª©ë¡', index=False)
    
    output.seek(0)
    
    st.download_button(
        label="ğŸ“¥ ì „ì²´ ê²°ê³¼ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=output,
        file_name=f"AHP_Result_{selected_file.replace('.csv','')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        type="primary"
    )

    # --------------------------------------------------------------------------
    # 6. ê´€ë¦¬ ê¸°ëŠ¥ (ì‚­ì œ)
    # --------------------------------------------------------------------------
    st.divider()
    with st.expander("ğŸ—‘ï¸ ë°ì´í„° ê´€ë¦¬ (ì£¼ì˜)"):
        if st.button("í˜„ì¬ í”„ë¡œì íŠ¸ ë°ì´í„° ì‚­ì œ"):
            os.remove(file_path)
            st.success("ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
            st.rerun()
