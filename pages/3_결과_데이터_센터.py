import streamlit as st
import pandas as pd
import numpy as np
import json
import io
import os
import re

# ==============================================================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==============================================================================
st.set_page_config(page_title="ê²°ê³¼ ë°ì´í„° ì„¼í„°", page_icon="ğŸ“Š", layout="wide")
st.title("ğŸ“Š AHP ê²°ê³¼ ë°ì´í„° ì„¼í„°")

# ë°ì´í„° ì €ì¥ì†Œ ê²½ë¡œ
DATA_FOLDER = "survey_data"
if not os.path.exists(DATA_FOLDER):
    os.makedirs(DATA_FOLDER)

# ==============================================================================
# [í•¨ìˆ˜] ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ & í–‰ë ¬ ë³´ì • ì—”ì§„
# ==============================================================================
def is_match(main_name, sub_task_name):
    """ëŒ€í•­ëª© ì´ë¦„ì´ ì†Œí•­ëª© ê·¸ë£¹ ì´ë¦„ì— í¬í•¨ë˜ëŠ”ì§€ ê²€ì‚¬"""
    clean_main = main_name.replace(" ", "").strip()
    clean_sub = sub_task_name.replace(" ", "").strip()
    if clean_main in clean_sub: return True
    match = re.search(r'\[(.*?)\]', sub_task_name)
    if match:
        extracted = match.group(1).replace(" ", "").strip()
        if extracted == clean_main: return True
    return False

def get_cr(matrix, n):
    """í–‰ë ¬ì˜ CRê°’ ê³„ì‚°"""
    try:
        eigvals, _ = np.linalg.eig(matrix)
        max_eigval = np.max(eigvals.real)
        ci = (max_eigval - n) / (n - 1) if n > 1 else 0
        ri_table = {1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45}
        ri = ri_table.get(n, 1.49)
        return ci / ri if ri != 0 else 0
    except:
        return 1.0

def calibrate_matrix(matrix, target_cr=0.1, max_iter=50, max_scale=5.0):
    """5ì  ì²™ë„ ì œí•œ ë³´ì • ì•Œê³ ë¦¬ì¦˜"""
    n = matrix.shape[0]
    curr_matrix = matrix.copy()
    
    for _ in range(max_iter):
        cr = get_cr(curr_matrix, n)
        if cr <= target_cr: break
            
        eigvals, eigvecs = np.linalg.eig(curr_matrix)
        max_idx = np.argmax(eigvals)
        w = eigvecs[:, max_idx].real
        w = w / w.sum()
        
        perfect_matrix = np.zeros((n, n))
        for i in range(n):
            for j in range(n):
                if w[j] != 0:
                    val = w[i] / w[j]
                    if val > max_scale: val = max_scale
                    if val < 1/max_scale: val = 1/max_scale
                    perfect_matrix[i][j] = val
                else:
                    perfect_matrix[i][j] = 1.0
                    
        alpha = 0.8 
        curr_matrix = alpha * curr_matrix + (1 - alpha) * perfect_matrix
        
        for i in range(n):
            for j in range(n):
                if curr_matrix[i][j] > max_scale: curr_matrix[i][j] = max_scale
                if curr_matrix[i][j] < 1/max_scale: curr_matrix[i][j] = 1/max_scale
        
        for i in range(n):
            curr_matrix[i][i] = 1.0
            for j in range(i+1, n):
                curr_matrix[j][i] = 1.0 / curr_matrix[i][j]
                
    return curr_matrix

# ==============================================================================
# [í•¨ìˆ˜] AHP ê³„ì‚°
# ==============================================================================
def calculate_ahp_metrics(comparisons, do_calibration=False, cr_limit=0.1, max_scale=5.0):
    norm_comps = {}
    items = set()
    for pair, val in comparisons.items():
        if " vs " in pair:
            a, b = pair.split(" vs ")
            a, b = a.strip(), b.strip()
            items.add(a); items.add(b)
            norm_comps[f"{a} vs {b}"] = float(val)
    items = sorted(list(items))
    n = len(items)
    item_map = {name: i for i, name in enumerate(items)}

    matrix = np.ones((n, n))
    for pair, val in norm_comps.items():
        try:
            a, b = pair.split(" vs ")
            if a in item_map and b in item_map:
                i, j = item_map[a], item_map[b]
                matrix[i][j] = val
                matrix[j][i] = 1 / val
        except: continue

    original_cr = get_cr(matrix, n)
    final_cr = original_cr
    was_calibrated = False

    if original_cr > cr_limit and do_calibration:
        matrix = calibrate_matrix(matrix, target_cr=cr_limit, max_scale=max_scale)
        final_cr = get_cr(matrix, n)
        was_calibrated = True

    try:
        eigvals, eigvecs = np.linalg.eig(matrix)
        max_idx = np.argmax(eigvals)
        weights = eigvecs[:, max_idx].real
        weights = weights / weights.sum()
    except:
        weights = np.ones(n) / n

    return items, weights, final_cr, was_calibrated

# ==============================================================================
# [UI] ì‚¬ì´ë“œë°”
# ==============================================================================
with st.sidebar:
    st.header("ğŸ”‘ ê´€ë¦¬ì ë©”ë‰´")
    user_key = st.text_input("í”„ë¡œì íŠ¸ ë¹„ë°€ë²ˆí˜¸", type="password")
    
    st.divider()
    st.subheader("ğŸ›ï¸ ë¶„ì„ ì˜µì…˜")
    auto_calibrate = st.checkbox("âœ¨ ë°ì´í„° ìë™ ë³´ì •", value=True)
    cr_threshold = st.slider("CR í—ˆìš© ê¸°ì¤€", 0.05, 0.5, 0.1, 0.05)
    max_scale_val = st.number_input("ìµœëŒ€ ë°°ìˆ˜ ì œí•œ", value=5.0, min_value=3.0, max_value=9.0)

if not user_key:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì— ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

all_files = [f for f in os.listdir(DATA_FOLDER) if f.endswith(".csv")]
my_files = [f for f in all_files if f.startswith(f"{user_key}_")]

if not my_files:
    st.error("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

selected_file = st.selectbox("ğŸ“‚ í”„ë¡œì íŠ¸ ì„ íƒ", my_files)

# ==============================================================================
# [ë©”ì¸] ë°ì´í„° ì²˜ë¦¬
# ==============================================================================
if selected_file:
    file_path = os.path.join(DATA_FOLDER, selected_file)
    raw_df = pd.read_csv(file_path)
    
    st.markdown(f"### ğŸ“„ í”„ë¡œì íŠ¸: **{selected_file.replace(user_key+'_', '').replace('.csv', '')}**")
    
    processed_data = []
    valid_weights = []
    task_crs = {} # íƒœìŠ¤í¬ë³„ í‰ê·  CR ì €ì¥ìš©
    
    calibrated_count = 0
    progress_bar = st.progress(0)
    
    for idx, row in raw_df.iterrows():
        try:
            survey_dict = json.loads(row['Raw_Data'])
            tasks = {}
            for k, v in survey_dict.items():
                if "]" in k:
                    split_idx = k.rfind("]")
                    task_name = k[1:split_idx]
                    pair = k[split_idx+1:].strip()
                    if task_name not in tasks: tasks[task_name] = {}
                    tasks[task_name][pair] = v
            
            is_valid = True
            resp_weights = {}
            resp_crs = {}
            is_resp_calibrated = False
            
            for t_name, comps in tasks.items():
                items, w, cr, calib = calculate_ahp_metrics(
                    comps, 
                    do_calibration=auto_calibrate, 
                    cr_limit=cr_threshold,
                    max_scale=max_scale_val
                )
                
                if cr > cr_threshold: is_valid = False
                if calib: is_resp_calibrated = True
                
                resp_crs[t_name] = cr
                for i, item in enumerate(items):
                    resp_weights[f"{t_name}|{item}"] = w[i]
                
                # CR ì§‘ê³„ (ìœ íš¨í•œ ê²½ìš°ë§Œ)
                if is_valid:
                    if t_name not in task_crs: task_crs[t_name] = []
                    task_crs[t_name].append(cr)
            
            status = "Valid"
            if not is_valid: status = "Invalid"
            elif is_resp_calibrated: status = "Calibrated"
            
            if is_resp_calibrated and is_valid: calibrated_count += 1
            
            processed_data.append({
                "Respondent": row['Respondent'],
                "Time": row['Time'],
                "Status": status,
                "Is_Valid": is_valid,
                "CR_Details": str(resp_crs),
                **resp_weights
            })
            
            if is_valid: valid_weights.append(resp_weights)
        except Exception: continue
        progress_bar.progress((idx + 1) / len(raw_df))
    
    progress_bar.empty()
    
    valid_df = pd.DataFrame(valid_weights)
    full_log_df = pd.DataFrame(processed_data)
    
    st.divider()
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì´ ì‘ë‹µ", f"{len(processed_data)}ëª…")
    c2.metric("âœ… ìœ íš¨ ë°ì´í„°", f"{len(valid_weights)}ëª…")
    c3.metric("âœ¨ 5ì ì²™ë„ ë³´ì •", f"{calibrated_count}ëª…")
    c4.metric("âŒ ì œì™¸ë¨", f"{len(processed_data) - len(valid_weights)}ëª…")

    if len(valid_weights) == 0:
        st.error("ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    avg_weights = valid_df.mean()
    tasks_unique = sorted(list(set([k.split("|")[0] for k in avg_weights.index])))
    if not tasks_unique: st.stop()
        
    main_task = tasks_unique[0]
    sub_tasks = tasks_unique[1:]
    
    final_rows = []
    
    # í‰ê·  CR ê³„ì‚° í•¨ìˆ˜
    def get_avg_cr(task_name):
        if task_name in task_crs and len(task_crs[task_name]) > 0:
            return np.mean(task_crs[task_name])
        return 0.0

    main_keys = [k for k in avg_weights.index if k.startswith(main_task)]
    main_items_data = []
    for k in main_keys:
        main_items_data.append({"name": k.split("|")[1], "weight": avg_weights[k]})
    main_items_data.sort(key=lambda x: x['weight'], reverse=True)

    # ëŒ€í•­ëª© CR
    main_cr = get_avg_cr(main_task)

    for m_item in main_items_data:
        m_name = m_item['name']
        m_weight = m_item['weight']
        
        matching_sub_task = None
        for st_name in sub_tasks:
            if is_match(m_name, st_name):
                matching_sub_task = st_name
                break
        
        if matching_sub_task:
            sub_cr = get_avg_cr(matching_sub_task)
            sub_keys = [k for k in avg_weights.index if k.startswith(matching_sub_task)]
            temp_subs = []
            for s_key in sub_keys:
                s_name = s_key.split("|")[1]
                s_weight = avg_weights[s_key]
                global_w = m_weight * s_weight
                temp_subs.append({"s_name": s_name, "s_weight": s_weight, "global_w": global_w})
            
            temp_subs.sort(key=lambda x: x['global_w'], reverse=True)
            
            for i, sub in enumerate(temp_subs):
                final_rows.append({
                    "ëŒ€í•­ëª©ëª…": m_name if i == 0 else "",      
                    "ëŒ€í•­ëª© ê°€ì¤‘ì¹˜": m_weight if i == 0 else None, 
                    "ì†Œí•­ëª©ëª…": sub['s_name'],
                    "ì†Œí•­ëª© ê°€ì¤‘ì¹˜": sub['s_weight'],
                    "ì¢…í•© ê°€ì¤‘ì¹˜": sub['global_w'],
                    "ìˆœìœ„": 0, # ë‚˜ì¤‘ì— ê³„ì‚°
                    "ê·¸ë£¹ CR": sub_cr, # ì†Œí•­ëª© ê·¸ë£¹ì˜ CR
                    "is_main_cr": False
                })
            
            # ëŒ€í•­ëª© í–‰ì— CR ì •ë³´ ì¶”ê°€ (ì²«ì¤„)
            # ì—¬ê¸°ì„œëŠ” êµ¬ì¡°ìƒ ëŒ€í•­ëª© í–‰ì„ ë”°ë¡œ ë§Œë“¤ì§€ ì•Šê³  ì²« ì†Œí•­ëª© ì˜†ì— ëŒ€í•­ëª© ì •ë³´ë¥¼ ë³‘í•©í–ˆìŒ.
            # í•˜ì§€ë§Œ CRì€ 'ëŒ€í•­ëª© CR'ê³¼ 'ì†Œí•­ëª© CR'ì´ ë‹¤ë¥´ë¯€ë¡œ êµ¬ë¶„ì´ í•„ìš”í•¨.
            # ì—‘ì…€ê³¼ í™”ë©´ì— 'ê·¸ë£¹ CR' ì»¬ëŸ¼ì„ ì¶”ê°€í•´ì„œ ë³´ì—¬ì¤Œ.
            
        else:
            final_rows.append({
                "ëŒ€í•­ëª©ëª…": m_name, "ëŒ€í•­ëª© ê°€ì¤‘ì¹˜": m_weight, 
                "ì†Œí•­ëª©ëª…": "-", "ì†Œí•­ëª© ê°€ì¤‘ì¹˜": None,
                "ì¢…í•© ê°€ì¤‘ì¹˜": m_weight, "ìˆœìœ„": 0,
                "ê·¸ë£¹ CR": main_cr, # ëŒ€í•­ëª© ìì²´ CR
                "is_main_cr": True
            })

    report_df = pd.DataFrame(final_rows)
    
    # [ìˆ˜ì •] ëŒ€í•­ëª©ì˜ CRì€ 'ëŒ€í•­ëª©ëª…'ì´ ìˆëŠ” í–‰(i=0)ì—ë§Œ í‘œì‹œí•˜ê±°ë‚˜, ë³„ë„ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„ë¦¬í•´ì•¼ í•¨.
    # ì—¬ê¸°ì„œëŠ” 'ê·¸ë£¹ CR' ì»¬ëŸ¼ì— í•´ë‹¹ ì†Œí•­ëª© ê·¸ë£¹ì˜ CRì„ í‘œì‹œí•˜ê³ , ëŒ€í•­ëª© CRì€ ë³„ë„ í‘œê¸° í•„ìš”.
    # í•˜ì§€ë§Œ í‘œ êµ¬ì¡°ìƒ ë³µì¡í•´ì§€ë¯€ë¡œ, 'ì†Œí•­ëª© CR'ì„ ìš°ì„  í‘œì‹œ.
    
    # ìˆœìœ„ ê³„ì‚°
    report_df['ìˆœìœ„'] = np.nan
    rank_mask = report_df['ì†Œí•­ëª©ëª…'] != "-"
    if rank_mask.any():
        report_df.loc[rank_mask, 'ìˆœìœ„'] = report_df.loc[rank_mask, 'ì¢…í•© ê°€ì¤‘ì¹˜'].rank(ascending=False).astype(int)
    
    # --------------------------------------------------------------------------
    # ì¶œë ¥
    # --------------------------------------------------------------------------
    st.subheader("ğŸ† ìµœì¢… ê°€ì¤‘ì¹˜ ë° ìˆœìœ„ ë¦¬í¬íŠ¸")
    
    # [NEW] ëŒ€í•­ëª© ê·¸ë£¹ì˜ í‰ê·  CR í‘œì‹œ
    st.info(f"ğŸ“Œ **1ë‹¨ê³„(ëŒ€í•­ëª©) í‰ê·  CR:** {main_cr:.4f}")
    
    display_cols = ["ëŒ€í•­ëª©ëª…", "ëŒ€í•­ëª© ê°€ì¤‘ì¹˜", "ì†Œí•­ëª©ëª…", "ì†Œí•­ëª© ê°€ì¤‘ì¹˜", "ì¢…í•© ê°€ì¤‘ì¹˜", "ìˆœìœ„", "ê·¸ë£¹ CR"]
    display_df = report_df[display_cols].copy()
    
    def fmt(x): return f"{x:.4f}" if pd.notnull(x) and x != "" else ""
    
    for c in ["ëŒ€í•­ëª© ê°€ì¤‘ì¹˜", "ì†Œí•­ëª© ê°€ì¤‘ì¹˜", "ì¢…í•© ê°€ì¤‘ì¹˜", "ê·¸ë£¹ CR"]:
        display_df[c] = display_df[c].apply(fmt)
        
    display_df["ìˆœìœ„"] = display_df["ìˆœìœ„"].apply(lambda x: f"{int(x)}ìœ„" if pd.notnull(x) else "")
    
    # ê·¸ë£¹ CR: ì†Œí•­ëª© ê·¸ë£¹ì˜ CRì„ ì˜ë¯¸. ëŒ€í•­ëª©ëª… ìˆëŠ” ì¤„ì— í‘œì‹œí•˜ì§€ ì•Šê³ , ì†Œí•­ëª© ì¤„ì— í‘œì‹œ.
    # ê°€ë…ì„±ì„ ìœ„í•´ ì²« ì¤„ì—ë§Œ í‘œì‹œí•˜ë„ë¡ ì²˜ë¦¬
    # (ì´ë¯¸ ë¡œì§ìƒ ê°™ì€ ì†Œí•­ëª© ê·¸ë£¹ë¼ë¦¬ ë¬¶ì—¬ìˆìœ¼ë¯€ë¡œ ì²« ì¤„ë§Œ ë‚¨ê¸°ê³  ì§€ì›Œë„ ë¨)
    
    # ì†Œí•­ëª©ëª…ì´ ë°”ë€ŒëŠ” ì§€ì  ì²´í¬í•´ì„œ ì¤‘ë³µ CR ì œê±°
    # Pandas ë¡œì§: ì†Œí•­ëª©ëª…ì´ ë°”ë€Œê±°ë‚˜, ëŒ€í•­ëª©ëª…ì´ ë°”ë€” ë•Œë§Œ CR í‘œì‹œ
    # (ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•˜ê²Œ ëª¨ë‘ í‘œì‹œí•˜ê±°ë‚˜, ì²« ì¤„ë§Œ í‘œì‹œ)
    
    st.dataframe(display_df, use_container_width=True, hide_index=True)
    
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        display_df.to_excel(writer, sheet_name='1_ìµœì¢…_ë¶„ì„_ê²°ê³¼', index=False)
        raw_df.to_excel(writer, sheet_name='2_ì „ì²´_ì›ë³¸_ë°ì´í„°', index=False)
        full_log_df[["Respondent", "Time", "Status", "CR_Details"]].to_excel(writer, sheet_name='3_ë°ì´í„°_ìƒíƒœ_ë¡œê·¸', index=False)
            
    st.download_button("ğŸ“¥ ì—‘ì…€ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ", output.getvalue(), f"Report_{selected_file.replace('.csv','')}.xlsx", "primary")

    st.divider()
    with st.expander("ğŸ—‘ï¸ ë°ì´í„° ì‚­ì œ"):
        if st.button("í˜„ì¬ ë°ì´í„° ì˜êµ¬ ì‚­ì œ"):
            os.remove(file_path); st.rerun()
