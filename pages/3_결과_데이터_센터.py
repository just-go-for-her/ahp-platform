import streamlit as st
import pandas as pd
import numpy as np
import json
import io
import os
import re
import requests # [ì¶”ê°€] êµ¬ê¸€ ì‹œíŠ¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ í•„ìš”

# ==============================================================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==============================================================================
st.set_page_config(page_title="ê²°ê³¼ ë°ì´í„° ì„¼í„°", page_icon="ğŸ“Š", layout="wide")
st.title("ğŸ“Š AHP ê²°ê³¼ ë°ì´í„° ì„¼í„°")

# ë°ì´í„° ì €ì¥ì†Œ ê²½ë¡œ
DATA_FOLDER = "survey_data"
if not os.path.exists(DATA_FOLDER):
    os.makedirs(DATA_FOLDER)

# [ì¶”ê°€] êµ¬ê¸€ ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_from_google_cloud(user_key):
    """
    êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ëœ ì „ì²´ ë°ì´í„° ì¤‘ í˜„ì¬ ì‚¬ìš©ìì˜ ë¹„ë°€ë²ˆí˜¸(user_key)ì™€ ì¼ì¹˜í•˜ëŠ” ê²ƒë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    WEBAPP_URL = "https://script.google.com/macros/s/AKfycbw-c1Cf71eSMFaouFhN_YziqOl05KBqZzt4-qOXFwkbFBUQrS4ADMozoIswYdAsQiIIOQ/exec"
    try:
        response = requests.get(WEBAPP_URL, params={"user_key": user_key}, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if data:
                return pd.DataFrame(data)
    except:
        pass
    return pd.DataFrame()

# ==============================================================================
# [í•¨ìˆ˜] ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ & í–‰ë ¬ ë³´ì • ì—”ì§„ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# ==============================================================================
def is_match(main_name, sub_task_name):
    clean_main = main_name.replace(" ", "").strip()
    clean_sub = sub_task_name.replace(" ", "").strip()
    if clean_main in clean_sub: return True
    match = re.search(r'\[(.*?)\]', sub_task_name)
    if match:
        extracted = match.group(1).replace(" ", "").strip()
        if extracted == clean_main: return True
    return False

def get_cr(matrix, n):
    try:
        eigvals, _ = np.linalg.eig(matrix)
        max_eigval = np.max(eigvals.real)
        ci = (max_eigval - n) / (n - 1) if n > 1 else 0
        ri_table = {1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45}
        ri = ri_table.get(n, 1.49)
        return ci / ri if ri != 0 else 0
    except:
        return 1.0

def calibrate_matrix(matrix, target_cr=0.1, max_iter=50, max_scale=5.0):
    n = matrix.shape[0]
    curr_matrix = matrix.copy()
    for _ in range(max_iter):
        cr = get_cr(curr_matrix, n)
        if cr <= target_cr: break
        eigvals, eigvecs = np.linalg.eig(curr_matrix)
        max_idx = np.argmax(eigvals)
        w = eigvecs[:, max_idx].real
        w = w / w.sum()
        perfect_matrix = np.zeros((n, n))
        for i in range(n):
            for j in range(n):
                if w[j] != 0:
                    val = w[i] / w[j]
                    if val > max_scale: val = max_scale
                    if val < 1/max_scale: val = 1/max_scale
                    perfect_matrix[i][j] = val
                else:
                    perfect_matrix[i][j] = 1.0
        alpha = 0.8 
        curr_matrix = alpha * curr_matrix + (1 - alpha) * perfect_matrix
        for i in range(n):
            for j in range(n):
                if curr_matrix[i][j] > max_scale: curr_matrix[i][j] = max_scale
                if curr_matrix[i][j] < 1/max_scale: curr_matrix[i][j] = 1/max_scale
        for i in range(n):
            curr_matrix[i][i] = 1.0
            for j in range(i+1, n):
                curr_matrix[j][i] = 1.0 / curr_matrix[i][j]
    return curr_matrix

def calculate_ahp_metrics(comparisons, do_calibration=False, cr_limit=0.1, max_scale=5.0):
    norm_comps = {}
    items = set()
    for pair, val in comparisons.items():
        if " vs " in pair:
            a, b = pair.split(" vs ")
            a, b = a.strip(), b.strip()
            items.add(a); items.add(b)
            norm_comps[f"{a} vs {b}"] = float(val)
    items = sorted(list(items))
    n = len(items)
    item_map = {name: i for i, name in enumerate(items)}
    matrix = np.ones((n, n))
    for pair, val in norm_comps.items():
        try:
            a, b = pair.split(" vs ")
            if a in item_map and b in item_map:
                i, j = item_map[a], item_map[b]
                matrix[i][j] = val
                matrix[j][i] = 1 / val
        except: continue
    original_cr = get_cr(matrix, n)
    final_cr = original_cr
    was_calibrated = False
    if original_cr > cr_limit and do_calibration:
        matrix = calibrate_matrix(matrix, target_cr=cr_limit, max_scale=max_scale)
        final_cr = get_cr(matrix, n)
        was_calibrated = True
    try:
        eigvals, eigvecs = np.linalg.eig(matrix)
        max_idx = np.argmax(eigvals)
        weights = eigvecs[:, max_idx].real
        weights = weights / weights.sum()
    except:
        weights = np.ones(n) / n
    return items, weights, final_cr, was_calibrated

# ==============================================================================
# [UI] ì‚¬ì´ë“œë°”
# ==============================================================================
with st.sidebar:
    st.header("ğŸ”‘ ê´€ë¦¬ì ë©”ë‰´")
    user_key = st.text_input("í”„ë¡œì íŠ¸ ë¹„ë°€ë²ˆí˜¸", type="password")
    st.divider()
    st.subheader("ğŸ›ï¸ ë¶„ì„ ì˜µì…˜")
    auto_calibrate = st.checkbox("âœ¨ ë°ì´í„° ìë™ ë³´ì •", value=True)
    cr_threshold = st.slider("CR í—ˆìš© ê¸°ì¤€", 0.05, 0.5, 0.1, 0.05)
    max_scale_val = st.number_input("ìµœëŒ€ ë°°ìˆ˜ ì œí•œ", value=5.0, min_value=3.0, max_value=9.0)

if not user_key:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì— ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

# íŒŒì¼ ëª©ë¡ ë° êµ¬ê¸€ ë³µêµ¬ ë²„íŠ¼
all_files = [f for f in os.listdir(DATA_FOLDER) if f.endswith(".csv")]
my_files = [f for f in all_files if f.startswith(f"{user_key}_")]

st.sidebar.divider()
if st.sidebar.button("â˜ï¸ êµ¬ê¸€ í´ë¼ìš°ë“œì—ì„œ ë³µêµ¬"):
    cloud_df = load_from_google_cloud(user_key)
    if not cloud_df.empty:
        st.session_state['cloud_data'] = cloud_df
        st.success("âœ… í´ë¼ìš°ë“œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    else:
        st.error("í´ë¼ìš°ë“œì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ==============================================================================
# [ë©”ì¸] ë°ì´í„° ë¡œë“œ (ì¸ì½”ë”© ì—ëŸ¬ ë° ë“¤ì—¬ì“°ê¸° êµì • ì™„ë£Œ)
# ==============================================================================
raw_df = pd.DataFrame()

if my_files:
    selected_file = st.selectbox("ğŸ“‚ ë¡œì»¬ í”„ë¡œì íŠ¸ ì„ íƒ", my_files)
    if selected_file:
        file_path = os.path.join(DATA_FOLDER, selected_file)
        try:
            # 1ìˆœìœ„: UTF-8 ì‹œë„
            raw_df = pd.read_csv(file_path, encoding='utf-8-sig')
        except UnicodeDecodeError:
            # 2ìˆœìœ„: CP949 ì‹œë„ (ì—‘ì…€ ì €ì¥ íŒŒì¼ìš©)
            raw_df = pd.read_csv(file_path, encoding='cp949')
        st.markdown(f"### ğŸ“„ í”„ë¡œì íŠ¸: **{selected_file.replace(user_key+'_', '').replace('.csv', '')}**")
elif 'cloud_data' in st.session_state:
    raw_df = st.session_state['cloud_data']
    st.markdown(f"### ğŸ“„ í´ë¼ìš°ë“œ ë³µêµ¬ ë°ì´í„° (ì´ {len(raw_df)}ê±´)")
else:
    st.error("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. [â˜ï¸ êµ¬ê¸€ í´ë¼ìš°ë“œì—ì„œ ë³µêµ¬]ë¥¼ ëˆŒëŸ¬ë³´ì„¸ìš”.")
    st.stop()

# ==============================================================================
# [ë©”ì¸] ë°ì´í„° ì²˜ë¦¬ ë° ì¶œë ¥ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
# ==============================================================================
if not raw_df.empty:
    processed_data = []
    valid_weights = []
    task_crs = {}
    calibrated_count = 0
    progress_bar = st.progress(0)
    
    for idx, row in raw_df.iterrows():
        try:
            survey_dict = json.loads(row['Raw_Data'])
            tasks = {}
            for k, v in survey_dict.items():
                if "]" in k:
                    split_idx = k.rfind("]")
                    task_name = k[1:split_idx]
                    pair = k[split_idx+1:].strip()
                    if task_name not in tasks: tasks[task_name] = {}
                    tasks[task_name][pair] = v
            
            is_valid = True
            resp_weights = {}
            resp_crs = {}
            is_resp_calibrated = False
            
            for t_name, comps in tasks.items():
                items, w, cr, calib = calculate_ahp_metrics(
                    comps, do_calibration=auto_calibrate, 
                    cr_limit=cr_threshold, max_scale=max_scale_val
                )
                if cr > cr_threshold: is_valid = False
                if calib: is_resp_calibrated = True
                resp_crs[t_name] = cr
                for i, item in enumerate(items):
                    resp_weights[f"{t_name}|{item}"] = w[i]
                if is_valid:
                    if t_name not in task_crs: task_crs[t_name] = []
                    task_crs[t_name].append(cr)
            
            status = "Valid"
            if not is_valid: status = "Invalid"
            elif is_resp_calibrated: status = "Calibrated"
            if is_resp_calibrated and is_valid: calibrated_count += 1
            
            processed_data.append({
                "Respondent": row['Respondent'], "Time": row['Time'],
                "Status": status, "Is_Valid": is_valid,
                "CR_Details": str(resp_crs), **resp_weights
            })
            if is_valid: valid_weights.append(resp_weights)
        except: continue
        progress_bar.progress((idx + 1) / len(raw_df))
    progress_bar.empty()

    if not valid_weights:
        st.error("ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); st.stop()

    valid_df = pd.DataFrame(valid_weights); full_log_df = pd.DataFrame(processed_data)
    st.divider()
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì´ ì‘ë‹µ", f"{len(processed_data)}ëª…")
    c2.metric("âœ… ìœ íš¨ ë°ì´í„°", f"{len(valid_weights)}ëª…")
    c3.metric("âœ¨ 5ì ì²™ë„ ë³´ì •", f"{calibrated_count}ëª…")
    c4.metric("âŒ ì œì™¸ë¨", f"{len(processed_data) - len(valid_weights)}ëª…")

    avg_weights = valid_df.mean()
    tasks_unique = sorted(list(set([k.split("|")[0] for k in avg_weights.index])))
    if tasks_unique:
        main_task = tasks_unique[0]; sub_tasks = tasks_unique[1:]; final_rows = []
        def get_avg_cr(task_name): return np.mean(task_crs[task_name]) if task_name in task_crs else 0.0
        
        main_cr = get_avg_cr(main_task)
        main_items = [{"name": k.split("|")[1], "w": avg_weights[k]} for k in avg_weights.index if k.startswith(main_task)]
        main_items.sort(key=lambda x: x['w'], reverse=True)

        for m in main_items:
            match_sub = next((s for s in sub_tasks if is_match(m['name'], s)), None)
            if match_sub:
                sub_cr = get_avg_cr(match_sub)
                s_keys = [k for k in avg_weights.index if k.startswith(match_sub)]
                subs = [{"n": k.split("|")[1], "w": avg_weights[k]} for k in s_keys]
                subs.sort(key=lambda x: (m['w'] * x['w']), reverse=True)
                for i, s in enumerate(subs):
                    final_rows.append({
                        "ëŒ€í•­ëª©ëª…": m['name'] if i == 0 else "", "ëŒ€í•­ëª© ê°€ì¤‘ì¹˜": m['w'] if i == 0 else None,
                        "ì†Œí•­ëª©ëª…": s['n'], "ì†Œí•­ëª© ê°€ì¤‘ì¹˜": s['w'], "ì¢…í•© ê°€ì¤‘ì¹˜": m['w'] * s['w'],
                        "ê·¸ë£¹ CR": sub_cr, "ìˆœìœ„": 0
                    })
            else:
                final_rows.append({
                    "ëŒ€í•­ëª©ëª…": m['name'], "ëŒ€í•­ëª© ê°€ì¤‘ì¹˜": m['w'], "ì†Œí•­ëª©ëª…": "-", 
                    "ì†Œí•­ëª© ê°€ì¤‘ì¹˜": None, "ì¢…í•© ê°€ì¤‘ì¹˜": m['w'], "ê·¸ë£¹ CR": main_cr, "ìˆœìœ„": 0
                })

        report_df = pd.DataFrame(final_rows)
        report_df['ìˆœìœ„'] = report_df['ì¢…í•© ê°€ì¤‘ì¹˜'].rank(ascending=False, method='min').astype(int)
        
        st.subheader("ğŸ† ìµœì¢… ê°€ì¤‘ì¹˜ ë° ìˆœìœ„ ë¦¬í¬íŠ¸")
        st.info(f"ğŸ“Œ **1ë‹¨ê³„(ëŒ€í•­ëª©) í‰ê·  CR:** {main_cr:.4f}")
        
        display_df = report_df.copy()
        for c in ["ëŒ€í•­ëª© ê°€ì¤‘ì¹˜", "ì†Œí•­ëª© ê°€ì¤‘ì¹˜", "ì¢…í•© ê°€ì¤‘ì¹˜", "ê·¸ë£¹ CR"]:
            display_df[c] = display_df[c].apply(lambda x: f"{x:.4f}" if pd.notnull(x) else "")
        display_df["ìˆœìœ„"] = display_df["ìˆœìœ„"].apply(lambda x: f"{x}ìœ„")
        
        st.dataframe(display_df, use_container_width=True, hide_index=True)
        
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            display_df.to_excel(writer, sheet_name='1_ìµœì¢…_ë¶„ì„_ê²°ê³¼', index=False)
            raw_df.to_excel(writer, sheet_name='2_ì „ì²´_ì›ë³¸_ë°ì´í„°', index=False)
        st.download_button("ğŸ“¥ ì—‘ì…€ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ", output.getvalue(), "Report_AHP.xlsx", "primary")

    st.divider()
    with st.expander("ğŸ—‘ï¸ ë°ì´í„° ì‚­ì œ"):
        if st.button("í˜„ì¬ ë°ì´í„° ì˜êµ¬ ì‚­ì œ"):
            if 'selected_file' in locals() and os.path.exists(file_path):
                os.remove(file_path); st.rerun()
