import streamlit as st
import pandas as pd
import json
import os
import re
import numpy as np

st.set_page_config(page_title="ê²°ê³¼ ë°ì´í„° ì„¼í„°", page_icon="ğŸ“Š", layout="wide")

st.title("ğŸ“Š ê²°ê³¼ ë°ì´í„° ì„¼í„°")
st.markdown("ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ **ë°ì´í„° ìœ íš¨ì„±(CR)**ì„ ê²€ì¦í•˜ê³  **ìµœì¢… ìˆœìœ„**ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤.")

DATA_FOLDER = "survey_data"

# ==============================================================================
# [AHP ê³„ì‚° ì—”ì§„] CR(ì¼ê´€ì„± ë¹„ìœ¨) ê³„ì‚° ì¶”ê°€
# ==============================================================================
# Saatyì˜ ë¬´ì‘ìœ„ ì§€ìˆ˜ (Random Index)
RI_TABLE = {1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45}

def saaty_scale(val):
    val = int(val)
    if val == 0: return 1
    elif val < 0: return 1 / (abs(val) + 1)
    else: return val + 1

def calculate_ahp(items, pairs_data):
    """ê°€ì¤‘ì¹˜ì™€ CR(ì¼ê´€ì„± ë¹„ìœ¨)ì„ ë™ì‹œì— ê³„ì‚°"""
    n = len(items)
    if n == 0: return {}, 0
    
    matrix = np.ones((n, n))
    item_map = {name: i for i, name in enumerate(items)}

    for key, val in pairs_data.items():
        if "_vs_" in key:
            parts = key.split("_vs_")
            item_a, item_b = parts[0], parts[1]
            if item_a in item_map and item_b in item_map:
                idx_a, idx_b = item_map[item_a], item_map[item_b]
                scale_val = saaty_scale(val)
                matrix[idx_a][idx_b] = scale_val
                matrix[idx_b][idx_a] = 1 / scale_val

    # 1. ê°€ì¤‘ì¹˜ ê³„ì‚° (ê¸°í•˜í‰ê· ë²•)
    geo_means = []
    for i in range(n):
        row_prod = np.prod(matrix[i])
        geo_means.append(row_prod ** (1/n))
    
    total_sum = sum(geo_means)
    weights = [gm / total_sum for gm in geo_means]
    weights_dict = {items[i]: w for i, w in enumerate(weights)}

    # 2. CR ê³„ì‚° (Lambda Max)
    if n <= 2:
        cr = 0.0
    else:
        # ê·¼ì‚¬ê°’ ê³„ì‚°: í–‰ë ¬ì˜ ì—´ í•©ê³„ * ê°€ì¤‘ì¹˜ í•©
        lambda_max = 0
        for i in range(n):
            col_sum = np.sum(matrix[:, i])
            lambda_max += col_sum * weights[i]
            
        ci = (lambda_max - n) / (n - 1)
        ri = RI_TABLE.get(n, 1.49)
        cr = ci / ri if ri != 0 else 0

    return weights_dict, cr

def process_single_response(raw_json):
    """í•œ ëª…ì˜ ì‘ë‹µ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¤‘ì¹˜ì™€ ìµœëŒ€ CR ë°˜í™˜"""
    data = json.loads(raw_json)
    groups, items_in_group = {}, {}

    # ë°ì´í„° íŒŒì‹±
    for full_key, val in data.items():
        match = re.match(r"\[(.*?)\](.*)", full_key)
        if match:
            group_name, pair_key = match.group(1), match.group(2)
            if group_name not in groups: 
                groups[group_name] = {}
                items_in_group[group_name] = set()
            groups[group_name][pair_key] = val
            if "_vs_" in pair_key:
                a, b = pair_key.split("_vs_")
                items_in_group[group_name].add(a)
                items_in_group[group_name].add(b)

    # ê³„ì‚° ìˆ˜í–‰
    calculated_weights = {}
    max_cr = 0.0 # ì´ ì‘ë‹µìì˜ CR ì¤‘ ê°€ì¥ ë‚˜ìœ(ë†’ì€) ê°’
    
    # (1) 1ì°¨ ê¸°ì¤€ ê³„ì‚°
    main_keys = [k for k in groups.keys() if "1" in k or "Main" in k or "ê¸°ì¤€" in k or "í‰ê°€" in k]
    # 'í‰ê°€' ë“±ì˜ ë‹¨ì–´ê°€ í¬í•¨ëœ ê·¸ë£¹ì„ 1ì°¨ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì • (ì„¤ë¬¸ ìƒì„± ì‹œ ì´ë¦„ ê·œì¹™ ì¤‘ìš”)
    # ì—¬ê¸°ì„œëŠ” ê°€ì¥ ë¨¼ì € ë‚˜ì˜¤ëŠ” ê·¸ë£¹ì„ 1ì°¨ë¡œ ê°€ì •í•˜ê±°ë‚˜ ì´ë¦„ìœ¼ë¡œ ë§¤ì¹­
    
    # 2ë²ˆ í˜ì´ì§€ ë¡œì§ì— ë”°ë¼ "ğŸ“‚ 1. í‰ê°€ ê¸°ì¤€..." ì´ë¦„ì´ ë¶™ìŒ
    main_group_name = next((k for k in groups.keys() if "1." in k), None)
    
    if main_group_name:
        items = list(items_in_group[main_group_name])
        w, cr = calculate_ahp(items, groups[main_group_name])
        calculated_weights["MAIN"] = w
        if cr > max_cr: max_cr = cr
    else:
        return None, 9.9 # 1ì°¨ ê¸°ì¤€ ì—†ìœ¼ë©´ ì—ëŸ¬ ì²˜ë¦¬

    # (2) 2ì°¨ ì„¸ë¶€ í•­ëª© ê³„ì‚° ë° ì¢…í•©
    final_rows = []
    
    for group_name, pairs in groups.items():
        if group_name == main_group_name: continue
        
        # ë¶€ëª¨ ì°¾ê¸° (ì´ë¦„ ë§¤ì¹­)
        parent_name = None
        for m_item in calculated_weights["MAIN"].keys():
            if m_item in group_name:
                parent_name = m_item
                break
        
        if parent_name:
            items = list(items_in_group[group_name])
            sub_w, sub_cr = calculate_ahp(items, pairs)
            
            if sub_cr > max_cr: max_cr = sub_cr
            
            p_weight = calculated_weights["MAIN"][parent_name]
            for s_item, s_weight in sub_w.items():
                final_rows.append({
                    "1ì°¨ ê¸°ì¤€": parent_name,
                    "1ì°¨ ê°€ì¤‘ì¹˜": p_weight,
                    "2ì°¨ í•­ëª©": s_item,
                    "2ì°¨ ê°€ì¤‘ì¹˜": s_weight,
                    "ì¢…í•© ê°€ì¤‘ì¹˜": p_weight * s_weight
                })

    return final_rows, max_cr

# ==============================================================================
# [UI ë° ë©”ì¸ ë¡œì§]
# ==============================================================================

if not os.path.exists(DATA_FOLDER):
    os.makedirs(DATA_FOLDER)

files = [f for f in os.listdir(DATA_FOLDER) if f.endswith(".csv")]

if files:
    selected_file = st.selectbox("ğŸ“‚ ë¶„ì„í•  í”„ë¡œì íŠ¸ ì„ íƒ:", files)
    
    if selected_file:
        file_path = os.path.join(DATA_FOLDER, selected_file)
        df = pd.read_csv(file_path)
        
        st.divider()
        st.subheader(f"ğŸ“ˆ í”„ë¡œì íŠ¸ ë¶„ì„: {selected_file.replace('.csv', '').replace('_', ' ')}")
        st.caption(f"ì´ ì‘ë‹µì: {len(df)}ëª…")
        
        if st.button("ğŸ§® ìœ íš¨ì„± ê²€ì‚¬ ë° ë¶„ì„ ì‹¤í–‰", type="primary"):
            
            valid_respondents_data = [] # Oì¸ ì‚¬ëŒë“¤ì˜ ë°ì´í„°ë§Œ ëª¨ìŒ
            respondent_status = []      # ì‚¬ëŒë³„ O/X í˜„í™©íŒ
            
            # 1. ì‚¬ëŒë³„ë¡œ CR ì²´í¬ ë° O/X íŒì •
            for idx, row in df.iterrows():
                try:
                    res_rows, person_max_cr = process_single_response(row['Raw_Data'])
                    
                    # íŒì • ë¡œì§ (CR <= 0.1 ì´ë©´ í†µê³¼)
                    is_valid = person_max_cr <= 0.1
                    valid_mark = "O" if is_valid else "X"
                    
                    status = {
                        "ì‘ë‹µì": row['Respondent'] if pd.notna(row['Respondent']) else f"ì°¸ì—¬ì {idx+1}",
                        "ì‘ì„±ì‹œê°„": row['Time'],
                        "ìµœëŒ€ CR": round(person_max_cr, 4),
                        "í™œìš© ì—¬ë¶€": valid_mark
                    }
                    respondent_status.append(status)
                    
                    if is_valid:
                        valid_respondents_data.extend(res_rows)
                        
                except Exception as e:
                    continue # ë°ì´í„° ì˜¤ë¥˜ ì‹œ ìŠ¤í‚µ

            # 2. ìœ íš¨ì„± ê²€ì‚¬ ê²°ê³¼í‘œ ì¶œë ¥
            st.markdown("### 1ï¸âƒ£ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ (Consistency Check)")
            st.caption("CR(ì¼ê´€ì„± ë¹„ìœ¨)ì´ 0.1 ì´í•˜ì¸ ë°ì´í„°ë§Œ 'O'ë¡œ íŒì •í•˜ì—¬ ë¶„ì„ì— í™œìš©í•©ë‹ˆë‹¤.")
            
            status_df = pd.DataFrame(respondent_status)
            
            # ìƒ‰ìƒ ì…íˆê¸° (OëŠ” íŒŒë‘, XëŠ” ë¹¨ê°•)
            def color_validity(val):
                color = '#e6fcf5' if val == 'O' else '#fff5f5' # ë°°ê²½ìƒ‰
                return f'background-color: {color}'

            st.dataframe(status_df.style.applymap(color_validity, subset=['í™œìš© ì—¬ë¶€']), use_container_width=True)
            
            # ìœ íš¨ ë°ì´í„° í†µê³„
            valid_count = len(status_df[status_df['í™œìš© ì—¬ë¶€'] == 'O'])
            st.info(f"ì´ {len(status_df)}ëª… ì¤‘ **{valid_count}ëª…(O)**ì˜ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ìˆœìœ„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.")

            # 3. ìµœì¢… ìˆœìœ„ ì‚°ì¶œ (ìœ íš¨ ë°ì´í„°ë§Œ ì‚¬ìš©)
            if valid_respondents_data:
                result_df = pd.DataFrame(valid_respondents_data)
                
                # í‰ê·  ê³„ì‚°
                final_df = result_df.groupby(['1ì°¨ ê¸°ì¤€', '2ì°¨ í•­ëª©']).mean(numeric_only=True).reset_index()
                final_df = final_df.sort_values(by='ì¢…í•© ê°€ì¤‘ì¹˜', ascending=False)
                final_df['ìˆœìœ„'] = range(1, len(final_df) + 1)
                
                display_df = final_df[['ìˆœìœ„', '1ì°¨ ê¸°ì¤€', '2ì°¨ í•­ëª©', 'ì¢…í•© ê°€ì¤‘ì¹˜', '1ì°¨ ê°€ì¤‘ì¹˜', '2ì°¨ ê°€ì¤‘ì¹˜']]
                
                st.divider()
                st.markdown("### ğŸ† 2ï¸âƒ£ ìµœì¢… ì¢…í•© ìˆœìœ„ (Global Rank)")
                st.dataframe(
                    display_df.style.format({
                        'ì¢…í•© ê°€ì¤‘ì¹˜': '{:.4f}', '1ì°¨ ê°€ì¤‘ì¹˜': '{:.4f}', '2ì°¨ ê°€ì¤‘ì¹˜': '{:.4f}'
                    }).background_gradient(subset=['ì¢…í•© ê°€ì¤‘ì¹˜'], cmap='Blues'),
                    use_container_width=True
                )
                
                # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ (3ê°œ ì‹œíŠ¸: ì¢…í•©ìˆœìœ„, ìœ íš¨ì„±ê²€ì‚¬, ì›ë³¸)
                import io
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    display_df.to_excel(writer, index=False, sheet_name='ì¢…í•©ìˆœìœ„_ê²°ê³¼')
                    status_df.to_excel(writer, index=False, sheet_name='ë°ì´í„°_ìœ íš¨ì„±_ê²€ì‚¬')
                    df.to_excel(writer, index=False, sheet_name='ì›ë³¸_ë°ì´í„°')
                
                st.download_button(
                    label="ğŸ“¥ ì „ì²´ ë¶„ì„ ê²°ê³¼ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                    data=output.getvalue(),
                    file_name=f"Final_Report_{selected_file.replace('.csv', '.xlsx')}",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    type="primary"
                )
            else:
                st.error("ë¶„ì„ì— í™œìš©í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ ë°ì´í„°(O)ê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤. ì„¤ë¬¸ì„ ë‹¤ì‹œ ì§„í–‰í•´ì£¼ì„¸ìš”.")
        
        with st.expander("ğŸ“‹ ì›ë³¸ ë°ì´í„° í™•ì¸"):
            st.dataframe(df)

else:
    st.info("ğŸ“­ ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì„¤ë¬¸ì„ ë¨¼ì € ì§„í–‰í•´ì£¼ì„¸ìš”.")
